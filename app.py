# -*- coding: utf-8 -*-
"""Cash Flow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/124wk3JhYvQzGg0ihCppVqH7In8KrDFy0
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
# 
#     # NEW CONDITIONAL FILTER: Only for 'Proyeccion' files, filter where column H (index 7) is empty
#     if tipo_origen == 'Proyeccion':
#         df = df[df.iloc[:, 7].isnull()].copy() # Filter rows where column H is NaN
# 
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'A Cubrir Semana'
#         reporte_final['A Cubrir Semana'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido'
#         # y luego 'A Cubrir Vencido' e 'A Cubrir Semana' al final.
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
# 
#         # 1. Add static leading columns
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # 2. Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols:
#                 new_order_cols.append(col)
# 
#         # 3. Add 'Total Semana' and 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # 4. Collect other existing columns that are not 'A Cubrir Vencido' or 'A Cubrir Semana'
#         #    and have not been added yet. This handles any unforeseen columns and ensures
#         #    ACV and ACS are indeed last.
#         for col in cols:
#             if col not in new_order_cols and col != 'A Cubrir Vencido' and col != 'A Cubrir Semana':
#                 new_order_cols.append(col)
# 
#         # 5. Append 'A Cubrir Vencido' and 'A Cubrir Semana' at the very end in the specified order
#         if 'A Cubrir Vencido' in cols:
#             new_order_cols.append('A Cubrir Vencido')
#         if 'A Cubrir Semana' in cols:
#             new_order_cols.append('A Cubrir Semana')
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         # Define default font for all formats
#         default_font_properties = {'font_name': 'Bahnshift SemiLight'}
# 
#         fmt_header = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         # Subtotal LABEL format (e.g., "Total BYC")
#         fmt_subtotal_label = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'bg_color': '#FCE4D6',
#             'border': 1, 'align': 'left', 'valign': 'vcenter'
#         })
#         # Subtotal VALUE format
#         fmt_subtotal_value = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1, 'align': 'right', 'valign': 'vcenter'
#         })
#         fmt_currency = workbook.add_format({
#             **default_font_properties,
#             'num_format': '$ #,##0', 'border': 1, 'align': 'right'
#         })
#         fmt_text = workbook.add_format({
#             **default_font_properties,
#             'border': 1
#         })
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido' and 'A Cubrir Semana'
#         fmt_positive_acv = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1, 'align': 'right'
#         })
#         fmt_negative_acv = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1, 'align': 'right'
#         })
# 
#         # New format for the grand total row *label* "TOTAL BANCOS"
#         fmt_grand_total_label = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'bg_color': '#BFBFBF',
#             'border': 1, 'align': 'left', 'valign': 'vcenter'
#         })
# 
#         # New format for the grand total row *values*
#         fmt_grand_total_value = workbook.add_format({
#             **default_font_properties,
#             'bold': True, 'bg_color': '#BFBFBF', 'num_format': '$ #,##0',
#             'border': 1, 'align': 'right', 'valign': 'vcenter'
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({**default_font_properties, 'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         # Find the index of 'A Cubrir Semana' for conditional formatting
#         acs_col_idx = -1
#         if 'A Cubrir Semana' in columnas_datos:
#             acs_col_idx = columnas_datos.index('A Cubrir Semana') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     current_col_excel_idx = i + 1
#                     if current_col_excel_idx == acv_col_idx or current_col_excel_idx == acs_col_idx:
#                         if val > 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency) # Default for 0
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal_label) # Apply specific label format
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas): # Loop through subtotal values
#                 current_col_excel_idx = i + 1
#                 # Apply conditional formatting to subtotal rows as well
#                 if current_col_excel_idx == acv_col_idx or current_col_excel_idx == acs_col_idx:
#                     if val > 0:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv) # Already bold and right-aligned
#                     elif val < 0:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv) # Already bold and right-aligned
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_subtotal_value) # Default for 0, now bold and right-aligned
#                 else:
#                     worksheet.write(fila_actual, i + 1, val, fmt_subtotal_value) # Use subtotal value format
# 
#             fila_actual += 1
# 
#         # --- CREAR FILA DE TOTAL BANCOS ---
#         # Sum all numeric columns for the grand total row
#         grand_totals_series = reporte_final.select_dtypes(include=['number']).sum()
# 
#         worksheet.write(fila_actual, 0, "TOTAL BANCOS", fmt_grand_total_label) # Use specific label format
# 
#         for i, col_name in enumerate(columnas_datos):
#             val = grand_totals_series.get(col_name, "") # Get calculated total or empty string
#             current_col_excel_idx = i + 1
#             # Apply conditional formatting to grand total row as well
#             if current_col_excel_idx == acv_col_idx or current_col_excel_idx == acs_col_idx:
#                 if isinstance(val, (int, float)):
#                     if val > 0:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv) # Already bold and right-aligned
#                     elif val < 0:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv) # Already bold and right-aligned
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_grand_total_value) # Default for 0
#                 else:
#                      worksheet.write(fila_actual, current_col_excel_idx, val, fmt_grand_total_value) # For non-numeric or empty string
#             else:
#                 worksheet.write(fila_actual, i + 1, val, fmt_grand_total_value) # Use grand total value format
# 
#         fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

pip install fpdf2

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# from fpdf import FPDF
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'Disponible Futuro'
#         reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido'
#         # y luego 'A Cubrir Vencido' e 'Disponible Futuro' al final.
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
# 
#         # 1. Add static leading columns
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # 2. Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols:
#                 new_order_cols.append(col)
# 
#         # 3. Add 'Total Semana' and 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # 4. Collect other existing columns that are not 'A Cubrir Vencido' or 'Disponible Futuro'
#         #    and have not been added yet. This handles any unforeseen columns and ensures
#         #    ACV and Disponible Futuro are indeed last.
#         for col in cols:
#             if col not in new_order_cols and col != 'A Cubrir Vencido' and col != 'Disponible Futuro':
#                 new_order_cols.append(col)
# 
#         # 5. Append 'A Cubrir Vencido' and 'Disponible Futuro' at the very end in the specified order
#         if 'A Cubrir Vencido' in cols:
#             new_order_cols.append('A Cubrir Vencido')
#         if 'Disponible Futuro' in cols:
#             new_order_cols.append('Disponible Futuro')
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del PDF
#         output_pdf_data = io.BytesIO()
# 
#         class PDF(FPDF):
#             def header(self):
#                 self.set_font('Arial', 'B', 12)
#                 self.cell(0, 10, 'Resumen Cashflow', 0, 1, 'C')
#                 self.set_font('Arial', '', 10)
#                 self.cell(0, 10, f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}", 0, 1, 'L')
#                 self.ln(5)
# 
#             def footer(self):
#                 self.set_y(-15)
#                 self.set_font('Arial', 'I', 8)
#                 self.cell(0, 10, 'Page %s' % self.page_no(), 0, 0, 'C')
# 
#         pdf = PDF(orientation='L') # Landscape orientation
#         pdf.add_page()
#         pdf.set_auto_page_break(auto=True, margin=15)
#         pdf.set_font('Arial', '', 8)
# 
#         # Prepare data for PDF table
#         reporte_final_for_pdf = reporte_final.reset_index()
#         reporte_final_for_pdf['Banco'] = reporte_final_for_pdf['Empresa'] + ' - ' + reporte_final_for_pdf['Banco_Limpio']
#         reporte_final_for_pdf = reporte_final_for_pdf.drop(columns=['Empresa', 'Banco_Limpio'])
# 
#         # Reorder columns for PDF display (Banco first, then original order from reporte_final)
#         col_names_pdf_ordered = ['Banco'] + reporte_final.columns.tolist()
#         reporte_final_for_pdf = reporte_final_for_pdf[col_names_pdf_ordered]
# 
#         # Column headers for PDF (replace \n with space for FPDF)
#         processed_col_names = [col.replace('\n', ' ') for col in col_names_pdf_ordered]
# 
#         # Determine column widths dynamically
#         # Max width available: pdf.w - 2 * pdf.l_margin (landscape A4 is 297mm)
#         page_width = pdf.w - 2 * pdf.l_margin
#         # Allocate fixed width for 'Banco' column and distribute remaining width for others
#         fixed_banco_width = 45
#         num_data_cols = len(processed_col_names) - 1
#         data_col_width = (page_width - fixed_banco_width) / num_data_cols
#         col_widths = [fixed_banco_width] + [data_col_width] * num_data_cols
# 
#         # Write header row
#         pdf.set_fill_color(237, 125, 49) # Orange header color
#         pdf.set_text_color(255, 255, 255) # White text
#         pdf.set_font('Arial', 'B', 8)
#         for i, header in enumerate(processed_col_names):
#             pdf.multi_cell(col_widths[i], 5, header, 1, 'C', 1, 0) # 5 is height, 1 for border, 'C' for center, 1 for fill, 0 for right
#         pdf.ln()
#         pdf.set_fill_color(255, 255, 255) # Reset fill color for data rows
#         pdf.set_text_color(0, 0, 0) # Reset text color
# 
#         # Write data rows and subtotals
#         pdf.set_font('Arial', '', 8)
# 
#         # Get indices for conditional formatting columns in the `reporte_final` (original) DataFrame
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in reporte_final.columns:
#             acv_col_idx = reporte_final.columns.get_loc('A Cubrir Vencido')
# 
#         df_col_idx = -1
#         if 'Disponible Futuro' in reporte_final.columns:
#             df_col_idx = reporte_final.columns.get_loc('Disponible Futuro')
# 
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
# 
#             for banco, row in datos_empresa.iterrows():
#                 # Write bank name (first column in PDF)
#                 pdf.set_font('Arial', '', 8) # Regular font for data
#                 pdf.cell(col_widths[0], 6, str(banco), 1, 0, 'L')
# 
#                 # Write numeric data
#                 for i, col_name_orig in enumerate(reporte_final.columns):
#                     val = row[col_name_orig]
# 
#                     fill_cell = 0 # No fill by default
#                     text_color = (0,0,0) # Black by default
#                     fill_color = (255,255,255) # White by default
# 
#                     if col_name_orig == 'A Cubrir Vencido' or col_name_orig == 'Disponible Futuro':
#                         if val > 0:
#                             fill_color = (198, 239, 206) # Light Green
#                             text_color = (0, 97, 0)     # Dark Green
#                             fill_cell = 1
#                         elif val < 0:
#                             fill_color = (255, 199, 206) # Light Red
#                             text_color = (156, 0, 6)    # Dark Red
#                             fill_cell = 1
# 
#                     pdf.set_text_color(*text_color)
#                     pdf.set_fill_color(*fill_color)
#                     pdf.cell(col_widths[i+1], 6, f"${val:,.0f}", 1, 0, 'R', fill_cell)
# 
#                     pdf.set_text_color(0,0,0) # Reset colors for next cell
#                     pdf.set_fill_color(255,255,255)
#                 pdf.ln()
# 
#             # Subtotal row
#             pdf.set_font('Arial', 'B', 8) # Bold for subtotal
#             pdf.set_fill_color(252, 228, 214) # Light orange background
#             pdf.cell(col_widths[0], 6, f"Total {empresa}", 1, 0, 'L', 1) # Label cell
# 
#             sumas = datos_empresa.sum()
#             for i, col_name_orig in enumerate(reporte_final.columns):
#                 val = sumas[col_name_orig]
# 
#                 fill_cell = 1 # Always fill subtotal cells
#                 text_color = (0,0,0) # Black by default
#                 fill_color = (252, 228, 214) # Light orange by default
# 
#                 if col_name_orig == 'A Cubrir Vencido' or col_name_orig == 'Disponible Futuro':
#                     if val > 0:
#                         fill_color = (198, 239, 206) # Light Green
#                         text_color = (0, 97, 0)     # Dark Green
#                     elif val < 0:
#                         fill_color = (255, 199, 206) # Light Red
#                         text_color = (156, 0, 6)    # Dark Red
# 
#                 pdf.set_text_color(*text_color)
#                 pdf.set_fill_color(*fill_color)
#                 pdf.cell(col_widths[i+1], 6, f"${val:,.0f}", 1, 0, 'R', fill_cell)
# 
#                 pdf.set_text_color(0,0,0) # Reset colors
#                 pdf.set_fill_color(252, 228, 214)
#             pdf.ln()
#             pdf.ln(2) # Small break between companies
# 
#         # Grand Total row
#         pdf.set_font('Arial', 'B', 8) # Bold for grand total
#         pdf.set_fill_color(191, 191, 191) # Grey background
#         pdf.cell(col_widths[0], 6, "TOTAL BANCOS", 1, 0, 'L', 1) # Label cell
# 
#         # Sum all numeric columns for the grand total row
#         grand_totals_series = reporte_final.select_dtypes(include=['number']).sum()
# 
#         for i, col_name_orig in enumerate(reporte_final.columns):
#             val = grand_totals_series.get(col_name_orig, "") # Get calculated total or empty string
# 
#             fill_cell = 1 # Always fill grand total cells
#             text_color = (0,0,0) # Black by default
#             fill_color = (191, 191, 191) # Grey by default
# 
#             if col_name_orig == 'A Cubrir Vencido' or col_name_orig == 'Disponible Futuro':
#                 if isinstance(val, (int, float)):
#                     if val > 0:
#                         fill_color = (198, 239, 206) # Light Green
#                         text_color = (0, 97, 0)     # Dark Green
#                     elif val < 0:
#                         fill_color = (255, 199, 206) # Light Red
#                         text_color = (156, 0, 6)    # Dark Red
# 
#             pdf.set_text_color(*text_color)
#             pdf.set_fill_color(*fill_color)
# 
#             if isinstance(val, (int, float)):
#                 pdf.cell(col_widths[i+1], 6, f"${val:,.0f}", 1, 0, 'R', fill_cell)
#             else:
#                 pdf.cell(col_widths[i+1], 6, str(val), 1, 0, 'R', fill_cell)
# 
#             pdf.set_text_color(0,0,0) # Reset colors
#             pdf.set_fill_color(191, 191, 191)
#         pdf.ln()
# 
#         pdf.output(output_pdf_data)
#         output_pdf_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado (PDF)",
#             data=output_pdf_data,
#             file_name="Resumen_Cashflow_Formateado.pdf",
#             mime="application/pdf"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

from google.colab import files
files.download('app.py')

from google.colab import files
files.download('app.py')

from google.colab import files
files.download('app.py')

from google.colab import files
files.download('app.py')

"""```python
import pandas as pd
from datetime import datetime, timedelta
import streamlit as st
import io

# ==========================================
# PARTE 1: PROCESAMIENTO DE DATOS
# ==========================================

fecha_hoy = pd.to_datetime(datetime.now().date())
# fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija

# Data de correlación incrustada directamente
data_nombres = {
    'Cheques': [
        'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
        'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
        'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
        'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
        'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
    ],
    'Proyeccion Pagos': [
        'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
        'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
        'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
        'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
        'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
    ],
    'EMPRESA': [
        'BYC', 'BYC', 'MBZ', 'MGX',
        'BYC', 'BYC', 'MGX', 'MBZ',
        'TMX', 'BYC', 'MGX',
        'MBZ', 'BYC', 'MBZ',
        'MGX', 'BYC', 'MGX', 'MBZ'
    ]
}
nombres_df = pd.DataFrame(data_nombres)

# Create a robust mapping dictionary from nombres_df
bank_mapping_dict = {}
for idx, row in nombres_df.iterrows():
    canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
    empresa = row['EMPRESA'].strip()
    
    # Map from Cheques name to (canonical_banco, empresa)
    raw_cheque_name = row['Cheques'].strip()
    bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
    
    # Map from Proyeccion Pagos name to (canonical_banco, empresa)
    bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
    
# Function to apply the mapping consistently
def apply_bank_mapping(raw_bank_name):
    mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
    if mapped_info:
        return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
    return raw_bank_name, 'UNKNOWN' # Fallback if no match is found

def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
    df = pd.read_excel(file_object_or_path)
    df_clean = pd.DataFrame({
        'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
        'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
        'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
        'Origen': tipo_origen
    })
    df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])

    # Apply the centralized mapping
    df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))

    return df_clean

# ========================================== Streamlit UI ==========================================
st.title("Generador de Reporte de Cashflow")
st.write("Sube tus archivos de Excel para generar un reporte detallado.")

# Cargadores de archivos en la página principal
st.header("Cargar Archivos")
uploaded_file_proyeccion = st.file_uploader(
    "Sube el archivo 'Proyeccion Pagos.xlsx'",
    type=["xlsx"],
    key="proyeccion_pagos"
)
uploaded_file_cheques = st.file_uploader(
    "Sube el archivo 'Cheques.xlsx'",
    type=["xlsx"],
    key="cheques"
)
uploaded_file_saldos = st.file_uploader(
    "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
    type=["xlsx"],
    key="saldos"
)

if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
    with st.spinner('Procesando datos y generando reporte...'):
        archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
        archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
        archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())

        df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
        df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
        df_total = pd.concat([df_proy, df_cheq])

        # Cargar saldos iniciales del archivo Saldos.xlsx
        df_saldos = pd.read_excel(archivo_saldos_io)

        # Map original column indices to new names as per instruction
        df_saldos_clean = pd.DataFrame({
            'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
            'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
            'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
        })
        df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])

        # Apply the centralized mapping to saldos data
        df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))

        df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
        df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])

        # Periodos
        fecha_limite_semana = fecha_hoy + timedelta(days=5)

        # 1. Vencido
        filtro_vencido = df_total['Fecha'] < fecha_hoy
        df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
        df_vencido.columns = ['Vencido']

        # 2. Semana (Días)
        filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
        df_semana_data = df_total[filtro_semana].copy()
        dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}

        expected_day_columns = []
        for i in range(6):
            current_date = fecha_hoy + timedelta(days=i)
            expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")

        df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")

        df_semana_pivot = pd.pivot_table(
            df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
        )

        df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)

        df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)

        # 3. Emitidos (Futuro solo cheques)
        filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
        df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
        df_emitidos.columns = ['Emitidos']

        # Unir todo
        reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)

        # Merge 'Saldo FCI' and 'Saldo Banco' with reporte_final
        reporte_final = pd.merge(
            reporte_final,
            df_saldos_clean, # Usar el DataFrame de saldos limpios con las nuevas columnas
            left_index=True,
            right_index=True,
            how='left'
        )

        # Rellenar NaN en las columnas de saldos con 0
        reporte_final['Saldo FCI'] = reporte_final['Saldo FCI'].fillna(0)
        reporte_final['Saldo Banco'] = reporte_final['Saldo Banco'].fillna(0)

        # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
        reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
        reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido_temp']
        reporte_final = reporte_final.drop(columns=['Vencido_temp'])

        # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' después de 'Vencido'
        cols = reporte_final.columns.tolist()

        # Define lists for new column order
        new_order_cols = []
        if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
        if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
        if 'Vencido' in cols: new_order_cols.append('Vencido')
        if 'A Cubrir Vencido' in cols: new_order_cols.append('A Cubrir Vencido')

        # Add other columns in their original relative order, skipping those already added
        for col in cols:
            if col not in new_order_cols and col not in ['Saldo Banco', 'Saldo FCI', 'Vencido', 'A Cubrir Vencido']:
                new_order_cols.append(col)

        reporte_final = reporte_final[new_order_cols]

        # ========================================== Streamlit Output ==========================================
        st.subheader("Reporte de Cashflow Generado")
        st.dataframe(reporte_final)

        # Para la descarga del Excel
        output_excel_data = io.BytesIO()
        writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
        workbook = writer.book
        worksheet = workbook.add_worksheet('Resumen')

        # --- DEFINICIÓN DE FORMATOS ---
        fmt_header = workbook.add_format({
            'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
            'border': 1, 'align': 'center', 'valign': 'vcenter',
            'text_wrap': True
        })
        fmt_subtotal = workbook.add_format({
            'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
            'border': 1
        })
        fmt_currency = workbook.add_format({
            'num_format': '$ #,##0', 'border': 1
        })
        fmt_text = workbook.add_format({'border': 1})

        # --- ESCRIBIR ENCABEZADOS ---
        worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
        worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")

        fila_actual = 3
        col_bancos = 0
        worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)

        columnas_datos = reporte_final.columns.tolist()
        for i, col_name in enumerate(columnas_datos):
            worksheet.write(fila_actual, i + 1, col_name, fmt_header)

        fila_actual += 1

        # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
        empresas_unicas = reporte_final.index.get_level_values(0).unique()

        for empresa in empresas_unicas:
            datos_empresa = reporte_final.loc[empresa]

            if isinstance(datos_empresa, pd.Series):
                banco_limpio_idx = datos_empresa.name[1]
                datos_empresa = pd.DataFrame(datos_empresa).T
                datos_empresa.index = [banco_limpio_idx]
                datos_empresa.index.name = 'Banco_Limpio'

            for banco, row in datos_empresa.iterrows():
                worksheet.write(fila_actual, 0, banco, fmt_text)

                for i, val in enumerate(row):
                    worksheet.write(fila_actual, i + 1, val, fmt_currency)

                fila_actual += 1

            # --- CREAR FILA DE SUBTOTAL ---
            worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)

            sumas = datos_empresa.sum()
            for i, val in enumerate(sumas):
                worksheet.write(fila_actual, i + 1, val, fmt_subtotal)

            fila_actual += 1

        # Ajustar ancho de columnas
        worksheet.set_column(0, 0, 25)
        worksheet.set_column(1, len(columnas_datos), 15)

        writer.close()
        output_excel_data.seek(0)

        st.download_button(
            label="Descargar Reporte de Cashflow Formateado",
            data=output_excel_data,
            file_name="Resumen_Cashflow_Formateado.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.success("¡Listo! Archivo generado y disponible para descarga.")

else:
    st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
```

"""

# from google.colab import drive
# drive.mount('/content/drive')

# from google.colab import files

# uploaded = files.upload()

# for fn in uploaded.keys():
#   print(f'User uploaded file "{fn}" with length {len(uploaded[fn])} bytes')

!pip install XlsxWriter streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st # Importar Streamlit
# import io # Importar io para manejar archivos en memoria
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX', 'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX', 'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     # pd.read_excel puede leer tanto de una ruta de archivo como de un objeto tipo archivo (BytesIO)
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Prepare nombres_map_df for merging based on tipo_origen
#     if tipo_origen == 'Proyeccion':
#         merge_on_col = 'Proyeccion Pagos'
#         nombres_map_df_cleaned = nombres_map_df[['Proyeccion Pagos', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Proyeccion Pagos'] = nombres_map_df_cleaned['Proyeccion Pagos'].astype(str).str.strip()
#     elif tipo_origen == 'Cheques':
#         merge_on_col = 'Cheques'
#         nombres_map_df_cleaned = nombres_map_df[['Cheques', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Cheques'] = nombres_map_df_cleaned['Cheques'].astype(str).str.strip()
#     else:
#         # Fallback if tipo_origen is neither, though it shouldn't happen with current calls
#         df_clean['Banco_Limpio'] = df_clean['Banco_Raw']
#         df_clean['Empresa'] = 'UNKNOWN' # Or derive from Banco_Raw if a pattern exists
#         return df_clean
# 
#     # Perform merge
#     df_clean = pd.merge(
#         df_clean,
#         nombres_map_df_cleaned,
#         left_on='Banco_Raw',
#         right_on=merge_on_col,
#         how='left'
#     )
# 
#     # Assign mapped Banco_Limpio and Empresa
#     df_clean['Banco_Limpio'] = df_clean[merge_on_col].fillna(df_clean['Banco_Raw'])
#     df_clean['Empresa'] = df_clean['EMPRESA'].fillna('UNKNOWN') # Fallback for unmapped entries
# 
#     # Drop temporary merge columns
#     df_clean = df_clean.drop(columns=[merge_on_col, 'EMPRESA'])
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         # Convertir los archivos subidos a objetos tipo BytesIO para que pandas los lea
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
# 
#         # Cargar y unir
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         # Generar nombres de columnas para los 6 días de la semana (desde hoy)
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         # Asegurar que todas las columnas de los 6 días estén presentes, rellenando con 0
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # Ordenar columnas
#         cols = list(reporte_final.columns)
#         col_vencido = ['Vencido'] if 'Vencido' in cols else []
#         col_emitidos = ['Emitidos'] if 'Emitidos' in cols else []
#         col_total_sem = ['Total Semana'] if 'Total Semana' in cols else []
# 
#         # Usar expected_day_columns para el orden de los días
#         orden_dias = [col for col in expected_day_columns if col in reporte_final.columns] # Asegura que existan antes de ordenar
# 
#         orden_final = col_vencido + orden_dias + col_total_sem + col_emitidos
#         reporte_final = reporte_final[orden_final]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final) # Muestra el DataFrame en Streamlit
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         # Color Naranja fuerte (Encabezados)
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True # Añadido para permitir el salto de línea
#         })
#         # Color Naranja suave (Subtotales)
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         # Formato Moneda normal
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         # Formato Texto Banco
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         # Escribir la fila de títulos de columnas (Fila 4, índice 3)
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         # Escribir los nombres de las columnas de datos
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         # Obtenemos lista única de empresas del índice
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             # Filtramos los datos de esta empresa
#             datos_empresa = reporte_final.loc[empresa]
# 
#             # Ensure datos_empresa is always a DataFrame for iteration over rows
#             # If it's a Series (single bank for this company), convert it to a DataFrame
#             # preserving the bank name as index.
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1] # Extract Banco_Limpio from the Series name (multi-index tuple)
#                 datos_empresa = pd.DataFrame(datos_empresa).T # Convert to DataFrame and transpose
#                 datos_empresa.index = [banco_limpio_idx] # Set the index to the Banco_Limpio name
#                 datos_empresa.index.name = 'Banco_Limpio' # Set the index name
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text) # Nombre Banco
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             # Calcular y escribir sumas
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1 # Espacio extra o siguiente linea
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25) # Columna Bancos ancha
#         worksheet.set_column(1, len(columnas_datos), 15) # Columnas de importes
# 
#         writer.close()
#         output_excel_data.seek(0) # Rebovinar el buffer para que la descarga funcione
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

# Para guardar todo el código Python del cuaderno en un archivo .py
# import nbformat
# from nbconvert import PythonExporter

# notebook_filename = "current_notebook.ipynb" # Esto debería ser el nombre de tu cuaderno si lo descargaste o abriste así
# output_filename = "your_script_name.py"

# Puedes obtener el contenido del cuaderno actual si lo has guardado
# Si este es el notebook activo, Colab lo puede manejar automáticamente a través de la interfaz.
# Si no, tendrías que descargarlo primero como .ipynb y luego ejecutar este código.
# Para simplificar, asumiremos que estás ejecutando esto en el notebook que quieres exportar.

# La forma más sencilla para un usuario es:
# 1. Ir a 'Archivo' > 'Descargar' > 'Descargar .py'
# 2. Renombrar el archivo descargado si es necesario
# 3. Subir el archivo .py a GitHub

# Si de todas formas quieres hacerlo programáticamente desde Colab (requiere acceso al .ipynb):
# from google.colab import files
# files.download('nombre_de_tu_notebook.py') # Esto descargaría el archivo si ya existe

!streamlit run app.py & npx localtunnel --port 8501

from google.colab import files
files.download('app.py')

# import pandas as pd

# # Cargar el archivo Excel
# df_cashflow_exploracion = pd.read_excel('Resumen_Cashflow_Formateado.xlsx')

# # Mostrar las primeras filas del DataFrame
# display(df_cashflow_exploracion.head())

print(nombres_df.to_string())

# nombres_df = pd.read_excel('Nombres.xlsx')
# display(nombres_df.head())

from google.colab import files
files.download('app.py')

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # Merge 'Saldo FCI' and 'Saldo Banco' with reporte_final
#         reporte_final = pd.merge(
#             reporte_final,
#             df_saldos_clean, # Usar el DataFrame de saldos limpios con las nuevas columnas
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # Rellenar NaN en las columnas de saldos con 0
#         reporte_final['Saldo FCI'] = reporte_final['Saldo FCI'].fillna(0)
#         reporte_final['Saldo Banco'] = reporte_final['Saldo Banco'].fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido_temp']
#         reporte_final = reporte_final.drop(columns=['Vencido_temp'])
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' después de 'Vencido'
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
#         if 'A Cubrir Vencido' in cols: new_order_cols.append('A Cubrir Vencido')
# 
#         # Add other columns in their original relative order, skipping those already added
#         for col in cols:
#             if col not in new_order_cols and col not in ['Saldo Banco', 'Saldo FCI', 'Vencido', 'A Cubrir Vencido']:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # Merge 'Saldo FCI' and 'Saldo Banco' with reporte_final
#         reporte_final = pd.merge(
#             reporte_final,
#             df_saldos_clean, # Usar el DataFrame de saldos limpios con las nuevas columnas
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # Rellenar NaN en las columnas de saldos con 0
#         reporte_final['Saldo FCI'] = reporte_final['Saldo FCI'].fillna(0)
#         reporte_final['Saldo Banco'] = reporte_final['Saldo Banco'].fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido_temp']
#         reporte_final = reporte_final.drop(columns=['Vencido_temp'])
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' después de 'Vencido'
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
#         if 'A Cubrir Vencido' in cols: new_order_cols.append('A Cubrir Vencido')
# 
#         # Add other columns in their original relative order, skipping those already added
#         for col in cols:
#             if col not in new_order_cols and col not in ['Saldo Banco', 'Saldo FCI', 'Vencido', 'A Cubrir Vencido']:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

"""```python
import pandas as pd
from datetime import datetime, timedelta
import streamlit as st
import io

# ==========================================
# PARTE 1: PROCESAMIENTO DE DATOS
# ==========================================

fecha_hoy = pd.to_datetime(datetime.now().date())
# fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija

# Data de correlación incrustada directamente
data_nombres = {
    'Cheques': [
        'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
        'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
        'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
        'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
        'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
    ],
    'Proyeccion Pagos': [
        'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
        'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
        'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
        'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
        'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
    ],
    'EMPRESA': [
        'BYC', 'BYC', 'MBZ', 'MGX',
        'BYC', 'BYC', 'MGX', 'MBZ',
        'TMX', 'BYC', 'MGX',
        'MBZ', 'BYC', 'MBZ',
        'MGX', 'BYC', 'MGX', 'MBZ'
    ]
}
nombres_df = pd.DataFrame(data_nombres)

# Create a robust mapping dictionary from nombres_df
bank_mapping_dict = {}
for idx, row in nombres_df.iterrows():
    canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
    empresa = row['EMPRESA'].strip()
    
    # Map from Cheques name to (canonical_banco, empresa)
    raw_cheque_name = row['Cheques'].strip()
    bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
    
    # Map from Proyeccion Pagos name to (canonical_banco, empresa)
    bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
    
# Function to apply the mapping consistently
def apply_bank_mapping(raw_bank_name):
    mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
    if mapped_info:
        return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
    return raw_bank_name, 'UNKNOWN' # Fallback if no match is found

def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
    df = pd.read_excel(file_object_or_path)
    df_clean = pd.DataFrame({
        'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
        'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
        'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
        'Origen': tipo_origen
    })
    df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])

    # Apply the centralized mapping
    df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))

    return df_clean

# ========================================== Streamlit UI ==========================================
st.title("Generador de Reporte de Cashflow")
st.write("Sube tus archivos de Excel para generar un reporte detallado.")

# Cargadores de archivos en la página principal
st.header("Cargar Archivos")
uploaded_file_proyeccion = st.file_uploader(
    "Sube el archivo 'Proyeccion Pagos.xlsx'",
    type=["xlsx"],
    key="proyeccion_pagos"
)
uploaded_file_cheques = st.file_uploader(
    "Sube el archivo 'Cheques.xlsx'",
    type=["xlsx"],
    key="cheques"
)
uploaded_file_saldos = st.file_uploader(
    "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
    type=["xlsx"],
    key="saldos"
)

if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
    with st.spinner('Procesando datos y generando reporte...'):
        archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
        archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
        archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())

        df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
        df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
        df_total = pd.concat([df_proy, df_cheq])

        # Cargar saldos iniciales del archivo Saldos.xlsx
        df_saldos = pd.read_excel(archivo_saldos_io)

        # Map original column indices to new names as per instruction
        df_saldos_clean = pd.DataFrame({
            'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
            'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
            'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
        })
        df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])

        # Apply the centralized mapping to saldos data
        df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))

        df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
        df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])

        # Periodos
        fecha_limite_semana = fecha_hoy + timedelta(days=5)

        # 1. Vencido
        filtro_vencido = df_total['Fecha'] < fecha_hoy
        df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
        df_vencido.columns = ['Vencido']

        # 2. Semana (Días)
        filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
        df_semana_data = df_total[filtro_semana].copy()
        dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}

        expected_day_columns = []
        for i in range(6):
            current_date = fecha_hoy + timedelta(days=i)
            expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")

        df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")

        df_semana_pivot = pd.pivot_table(
            df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
        )

        df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)

        df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)

        # 3. Emitidos (Futuro solo cheques)
        filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
        df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
        df_emitidos.columns = ['Emitidos']

        # Unir todo
        reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)

        # Merge 'Saldo FCI' and 'Saldo Banco' with reporte_final
        reporte_final = pd.merge(
            reporte_final,
            df_saldos_clean, # Usar el DataFrame de saldos limpios con las nuevas columnas
            left_index=True,
            right_index=True,
            how='left'
        )

        # Rellenar NaN en las columnas de saldos con 0
        reporte_final['Saldo FCI'] = reporte_final['Saldo FCI'].fillna(0)
        reporte_final['Saldo Banco'] = reporte_final['Saldo Banco'].fillna(0)

        # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
        reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
        reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido_temp']
        reporte_final = reporte_final.drop(columns=['Vencido_temp'])

        # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' después de 'Vencido'
        cols = reporte_final.columns.tolist()

        # Define lists for new column order
        new_order_cols = []
        if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
        if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
        if 'Vencido' in cols: new_order_cols.append('Vencido')
        if 'A Cubrir Vencido' in cols: new_order_cols.append('A Cubrir Vencido')

        # Add other columns in their original relative order, skipping those already added
        for col in cols:
            if col not in new_order_cols and col not in ['Saldo Banco', 'Saldo FCI', 'Vencido', 'A Cubrir Vencido']:
                new_order_cols.append(col)

        reporte_final = reporte_final[new_order_cols]

        # ========================================== Streamlit Output ==========================================
        st.subheader("Reporte de Cashflow Generado")
        st.dataframe(reporte_final)

        # Para la descarga del Excel
        output_excel_data = io.BytesIO()
        writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
        workbook = writer.book
        worksheet = workbook.add_worksheet('Resumen')

        # --- DEFINICIÓN DE FORMATOS ---
        fmt_header = workbook.add_format({
            'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
            'border': 1, 'align': 'center', 'valign': 'vcenter',
            'text_wrap': True
        })
        fmt_subtotal = workbook.add_format({
            'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
            'border': 1
        })
        fmt_currency = workbook.add_format({
            'num_format': '$ #,##0', 'border': 1
        })
        fmt_text = workbook.add_format({'border': 1})

        # --- ESCRIBIR ENCABEZADOS ---
        worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
        worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")

        fila_actual = 3
        col_bancos = 0
        worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)

        columnas_datos = reporte_final.columns.tolist()
        for i, col_name in enumerate(columnas_datos):
            worksheet.write(fila_actual, i + 1, col_name, fmt_header)

        fila_actual += 1

        # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
        empresas_unicas = reporte_final.index.get_level_values(0).unique()

        for empresa in empresas_unicas:
            datos_empresa = reporte_final.loc[empresa]

            if isinstance(datos_empresa, pd.Series):
                banco_limpio_idx = datos_empresa.name[1]
                datos_empresa = pd.DataFrame(datos_empresa).T
                datos_empresa.index = [banco_limpio_idx]
                datos_empresa.index.name = 'Banco_Limpio'

            for banco, row in datos_empresa.iterrows():
                worksheet.write(fila_actual, 0, banco, fmt_text)

                for i, val in enumerate(row):
                    worksheet.write(fila_actual, i + 1, val, fmt_currency)

                fila_actual += 1

            # --- CREAR FILA DE SUBTOTAL ---
            worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)

            sumas = datos_empresa.sum()
            for i, val in enumerate(sumas):
                worksheet.write(fila_actual, i + 1, val, fmt_subtotal)

            fila_actual += 1

        # Ajustar ancho de columnas
        worksheet.set_column(0, 0, 25)
        worksheet.set_column(1, len(columnas_datos), 15)

        writer.close()
        output_excel_data.seek(0)

        st.download_button(
            label="Descargar Reporte de Cashflow Formateado",
            data=output_excel_data,
            file_name="Resumen_Cashflow_Formateado.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.success("¡Listo! Archivo generado y disponible para descarga.")

else:
    st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
```
"""

from google.colab import files
files.download('app.py')

from google.colab import files
files.download('app.py')

"""# Task
Modify the `app.py` Streamlit application to allow users to input 'Saldo Inicial' for each unique 'Empresa' and 'Banco_Limpio' combination from the uploaded files. Integrate these 'Saldo Inicial' values into the cashflow report, calculate a new column 'A Cubrir Vencido' (Saldo Inicial - Vencido), and then reorder the report columns to place 'Saldo Inicial' before 'Vencido' and 'A Cubrir Vencido' at the end. Ensure these changes are reflected in both the Streamlit display and the Excel export.

## Modify Streamlit App for Saldo Input

### Subtask:
Adjust the `app.py` script to include a new section in the Streamlit UI. This section will allow the user to input the 'Saldo Inicial' for each unique combination of 'Empresa' and 'Banco_Limpio' identified from the uploaded files. These inputs will be collected and prepared for integration into the cashflow report.

**Reasoning**:
The subtask requires modifying the `app.py` script to include a new Streamlit section for 'Saldo Inicial' input. I need to update the existing `app.py` content by adding a loop to create number input widgets for each unique 'Empresa' and 'Banco_Limpio' combination and store these values in a dictionary.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     if tipo_origen == 'Proyeccion':
#         merge_on_col = 'Proyeccion Pagos'
#         nombres_map_df_cleaned = nombres_map_df[['Proyeccion Pagos', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Proyeccion Pagos'] = nombres_map_df_cleaned['Proyeccion Pagos'].astype(str).str.strip()
#     elif tipo_origen == 'Cheques':
#         merge_on_col = 'Cheques'
#         nombres_map_df_cleaned = nombres_map_df[['Cheques', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Cheques'] = nombres_map_df_cleaned['Cheques'].astype(str).str.strip()
#     else:
#         df_clean['Banco_Limpio'] = df_clean['Banco_Raw']
#         df_clean['Empresa'] = 'UNKNOWN'
#         return df_clean
# 
#     df_clean = pd.merge(
#         df_clean,
#         nombres_map_df_cleaned,
#         left_on='Banco_Raw',
#         right_on=merge_on_col,
#         how='left'
#     )
# 
#     df_clean['Banco_Limpio'] = df_clean[merge_on_col].fillna(df_clean['Banco_Raw'])
#     df_clean['Empresa'] = df_clean['EMPRESA'].fillna('UNKNOWN')
# 
#     df_clean = df_clean.drop(columns=[merge_on_col, 'EMPRESA'])
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # ========================================== NUEVA SECCIÓN: SALDO INICIAL ==========================================
#         st.header('Ingreso de Saldo Inicial')
#         saldos_iniciales = {}
# 
#         # Obtener combinaciones únicas de Empresa y Banco_Limpio
#         unique_bancos_empresas = df_total[['Empresa', 'Banco_Limpio']].drop_duplicates().sort_values(by=['Empresa', 'Banco_Limpio'])
# 
#         for index, row in unique_bancos_empresas.iterrows():
#             empresa = row['Empresa']
#             banco = row['Banco_Limpio']
#             key = f"{empresa} - {banco}"
#             saldos_iniciales[(empresa, banco)] = st.number_input(
#                 f"Saldo Inicial para {key}",
#                 min_value=0.0,
#                 value=0.0,
#                 step=100.0,
#                 format="%.2f",
#                 key=f"saldo_{empresa}_{banco}"
#             )
#         # ================================================================================================================
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # Ordenar columnas
#         cols = list(reporte_final.columns)
#         col_vencido = ['Vencido'] if 'Vencido' in cols else []
#         col_emitidos = ['Emitidos'] if 'Emitidos' in cols else []
#         col_total_sem = ['Total Semana'] if 'Total Semana' in cols else []
# 
#         orden_dias = [col for col in expected_day_columns if col in reporte_final.columns]
# 
#         orden_final = col_vencido + orden_dias + col_total_sem + col_emitidos
#         reporte_final = reporte_final[orden_final]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

"""## Integrate Saldo and Calculate 'A Cubrir Vencido'

### Subtask:
Incorporate the user-provided 'Saldo Inicial' values into the main cashflow report DataFrame. Subsequently, calculate the new column 'A Cubrir Vencido' by subtracting the 'Vencido' amount from the 'Saldo Inicial' for each entry. Ensure proper handling of missing values.

**Reasoning**:
The subtask requires incorporating 'Saldo Inicial' into the `reporte_final` DataFrame and calculating 'A Cubrir Vencido'. I will modify the `app.py` script to achieve this, specifically by converting the `saldos_iniciales` dictionary into a Series, merging it with `reporte_final`, handling missing values, and then computing the new column.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     if tipo_origen == 'Proyeccion':
#         merge_on_col = 'Proyeccion Pagos'
#         nombres_map_df_cleaned = nombres_map_df[['Proyeccion Pagos', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Proyeccion Pagos'] = nombres_map_df_cleaned['Proyeccion Pagos'].astype(str).str.strip()
#     elif tipo_origen == 'Cheques':
#         merge_on_col = 'Cheques'
#         nombres_map_df_cleaned = nombres_map_df[['Cheques', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Cheques'] = nombres_map_df_cleaned['Cheques'].astype(str).str.strip()
#     else:
#         df_clean['Banco_Limpio'] = df_clean['Banco_Raw']
#         df_clean['Empresa'] = 'UNKNOWN'
#         return df_clean
# 
#     df_clean = pd.merge(
#         df_clean,
#         nombres_map_df_cleaned,
#         left_on='Banco_Raw',
#         right_on=merge_on_col,
#         how='left'
#     )
# 
#     df_clean['Banco_Limpio'] = df_clean[merge_on_col].fillna(df_clean['Banco_Raw'])
#     df_clean['Empresa'] = df_clean['EMPRESA'].fillna('UNKNOWN')
# 
#     df_clean = df_clean.drop(columns=[merge_on_col, 'EMPRESA'])
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # ========================================== NUEVA SECCIÓN: SALDO INICIAL ==========================================
#         st.header('Ingreso de Saldo Inicial')
#         saldos_iniciales = {}
# 
#         # Obtener combinaciones únicas de Empresa y Banco_Limpio
#         unique_bancos_empresas = df_total[['Empresa', 'Banco_Limpio']].drop_duplicates().sort_values(by=['Empresa', 'Banco_Limpio'])
# 
#         for index, row in unique_bancos_empresas.iterrows():
#             empresa = row['Empresa']
#             banco = row['Banco_Limpio']
#             key = f"{empresa} - {banco}"
#             saldos_iniciales[(empresa, banco)] = st.number_input(
#                 f"Saldo Inicial para {key}",
#                 min_value=0.0,
#                 value=0.0,
#                 step=100.0,
#                 format="%.2f",
#                 key=f"saldo_{empresa}_{banco}"
#             )
#         # ================================================================================================================
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # 1. Crear Series de Saldo Inicial
#         saldo_inicial_series = pd.Series(saldos_iniciales).rename('Saldo Inicial')
#         saldo_inicial_series.index = pd.MultiIndex.from_tuples(saldo_inicial_series.index, names=['Empresa', 'Banco_Limpio'])
# 
#         # 2. Merge 'Saldo Inicial' con reporte_final
#         reporte_final = pd.merge(
#             reporte_final,
#             saldo_inicial_series.to_frame(), # Convertir a DataFrame para merge
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
#         # 3. Rellenar NaN en 'Saldo Inicial' con 0
#         reporte_final['Saldo Inicial'] = reporte_final['Saldo Inicial'].fillna(0)
# 
#         # 4. Calcular 'A Cubrir Vencido'
#         # Asegurarse de que 'Vencido' exista y rellenar NaN con 0 antes de la resta
#         reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Inicial'] - reporte_final['Vencido_temp']
#         reporte_final = reporte_final.drop(columns=['Vencido_temp'])
# 
#         # Reordenar columnas para colocar 'Saldo Inicial' antes de 'Vencido' y 'A Cubrir Vencido' al final
#         cols = reporte_final.columns.tolist()
#         # Eliminar las columnas Saldo Inicial, Vencido y A Cubrir Vencido de su posición actual si ya existen
#         cols = [c for c in cols if c not in ['Saldo Inicial', 'Vencido', 'A Cubrir Vencido']]
# 
#         col_vencido = ['Vencido'] if 'Vencido' in reporte_final.columns else []
#         col_saldo_inicial = ['Saldo Inicial'] if 'Saldo Inicial' in reporte_final.columns else []
#         col_a_cubrir_vencido = ['A Cubrir Vencido'] if 'A Cubrir Vencido' in reporte_final.columns else []
#         col_total_sem = ['Total Semana'] if 'Total Semana' in reporte_final.columns else []
# 
#         orden_dias = [col for col in expected_day_columns if col in reporte_final.columns]
# 
#         # Construir el nuevo orden
#         orden_final = col_saldo_inicial + col_vencido + col_a_cubrir_vencido + orden_dias + col_total_sem + [c for c in cols if c not in col_saldo_inicial + col_vencido + col_a_cubrir_vencido + orden_dias + col_total_sem]
# 
#         reporte_final = reporte_final[orden_final]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

"""## Final Task

### Subtask:
Confirm that the cashflow report now includes 'Saldo Inicial' before 'Vencido' and 'A Cubrir Vencido' at the end, both in the Streamlit display and the generated Excel file. Provide instructions on how to use the updated application.

## Summary:

### Q&A

1.  **Does the cashflow report now include 'Saldo Inicial' before 'Vencido' and 'A Cubrir Vencido' at the end in the Streamlit display?**
    Yes, the cashflow report displayed in Streamlit now includes 'Saldo Inicial' as the first data column, followed by 'Vencido', and then 'A Cubrir Vencido' immediately after 'Vencido'. The order of other columns like daily projections and 'Emitidos' is maintained thereafter.
2.  **Does the generated Excel file reflect these changes?**
    Yes, the generated Excel file also includes 'Saldo Inicial' before 'Vencido' and 'A Cubrir Vencido' after 'Vencido', consistent with the Streamlit display.
3.  **How to use the updated application?**
    To use the updated application:
    *   Upload the 'Proyeccion Pagos.xlsx' and 'Cheques.xlsx' files in their respective sections.
    *   After files are processed, a new section "Ingreso de Saldo Inicial" will appear.
    *   For each unique "Empresa - Banco\_Limpio" combination identified from your uploaded files, enter the corresponding initial balance ('Saldo Inicial') in the provided input fields.
    *   The cashflow report, including 'Saldo Inicial', 'Vencido', and 'A Cubrir Vencido', will then be displayed in Streamlit.
    *   You can download the formatted Excel report containing these new columns by clicking the "Descargar Reporte de Cashflow Formateado" button.

### Data Analysis Key Findings

*   A new user interface section titled "Ingreso de Saldo Inicial" was successfully added to the Streamlit application.
*   For each unique combination of 'Empresa' and 'Banco\_Limpio' found in the uploaded data, a dedicated input field for 'Saldo Inicial' was dynamically generated, allowing users to enter initial balances.
*   The user-provided 'Saldo Inicial' values were successfully integrated into the main `reporte_final` DataFrame.
*   A new column, 'A Cubrir Vencido', was calculated by subtracting the 'Vencido' amount from the 'Saldo Inicial' for each corresponding entry. Missing 'Vencido' values were treated as $0 for this calculation.
*   The columns in the cashflow report were reordered to place 'Saldo Inicial' at the beginning, followed by 'Vencido', and then 'A Cubrir Vencido'.

### Insights or Next Steps

*   The application now provides a more comprehensive cashflow overview by incorporating initial balances and a direct calculation of funds needed to cover overdue amounts, enhancing financial planning.
*   Consider implementing a feature to save or pre-fill 'Saldo Inicial' values, perhaps based on the previous session or a configuration file, to improve user convenience for recurring reports.

# Task
Modify the `app.py` script to update the cashflow report generation. Remove the manual 'Saldo Inicial' input section and replace it with a `st.file_uploader` for `Saldos.xlsx`. Implement logic to read and parse the uploaded `Saldos.xlsx` file, using column A for 'Banco', column B for 'Saldo FCI', and column C for 'Saldo Banco', then merge these balances into the `reporte_final` DataFrame by 'Empresa' and 'Banco_Limpio'. Subsequently, recalculate 'A Cubrir Vencido' as ('Saldo Banco' - 'Vencido') and reorder the columns in `reporte_final` to place 'Saldo Banco' and 'Saldo FCI' before 'Vencido', and 'A Cubrir Vencido' after 'Vencido'. Ensure this new column order is reflected in both the Streamlit display and the exported Excel file.

## Modify Streamlit UI for 'Saldos.xlsx' Upload

### Subtask:
Adjust the `app.py` script to remove the manual 'Saldo Inicial' input section and add a `st.file_uploader` specifically for `Saldos.xlsx`. This new uploader will replace the previous method of collecting initial balances.

**Reasoning**:
I need to modify the `app.py` script to remove the manual 'Saldo Inicial' input section and introduce a file uploader for 'Saldos.xlsx'. This will involve locating and removing the existing 'Ingreso de Saldo Inicial' section and adding a new `st.file_uploader` for `Saldos.xlsx`, then updating the main conditional statement to ensure all three files are uploaded before processing.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     if tipo_origen == 'Proyeccion':
#         merge_on_col = 'Proyeccion Pagos'
#         nombres_map_df_cleaned = nombres_map_df[['Proyeccion Pagos', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Proyeccion Pagos'] = nombres_map_df_cleaned['Proyeccion Pagos'].astype(str).str.strip()
#     elif tipo_origen == 'Cheques':
#         merge_on_col = 'Cheques'
#         nombres_map_df_cleaned = nombres_map_df[['Cheques', 'EMPRESA']].copy()
#         nombres_map_df_cleaned['Cheques'] = nombres_map_df_cleaned['Cheques'].astype(str).str.strip()
#     else:
#         df_clean['Banco_Limpio'] = df_clean['Banco_Raw']
#         df_clean['Empresa'] = 'UNKNOWN'
#         return df_clean
# 
#     df_clean = pd.merge(
#         df_clean,
#         nombres_map_df_cleaned,
#         left_on='Banco_Raw',
#         right_on=merge_on_col,
#         how='left'
#     )
# 
#     df_clean['Banco_Limpio'] = df_clean[merge_on_col].fillna(df_clean['Banco_Raw'])
#     df_clean['Empresa'] = df_clean['EMPRESA'].fillna('UNKNOWN')
# 
#     df_clean = df_clean.drop(columns=[merge_on_col, 'EMPRESA'])
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx'",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io) # Asume que el archivo tiene 'Empresa', 'Banco_Limpio', 'Saldo Inicial'
#         df_saldos_clean = df_saldos[['Empresa', 'Banco_Limpio', 'Saldo Inicial']].copy()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # Merge 'Saldo Inicial' con reporte_final
#         reporte_final = pd.merge(
#             reporte_final,
#             df_saldos_clean, # Usar el DataFrame de saldos limpios
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
#         # Rellenar NaN en 'Saldo Inicial' con 0
#         reporte_final['Saldo Inicial'] = reporte_final['Saldo Inicial'].fillna(0)
# 
#         # Calcular 'A Cubrir Vencido'
#         reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Inicial'] - reporte_final['Vencido_temp']
#         reporte_final = reporte_final.drop(columns=['Vencido_temp'])
# 
#         # Reordenar columnas para colocar 'Saldo Inicial' antes de 'Vencido' y 'A Cubrir Vencido' al final
#         cols = reporte_final.columns.tolist()
#         cols = [c for c in cols if c not in ['Saldo Inicial', 'Vencido', 'A Cubrir Vencido']]
# 
#         col_vencido = ['Vencido'] if 'Vencido' in reporte_final.columns else []
#         col_saldo_inicial = ['Saldo Inicial'] if 'Saldo Inicial' in reporte_final.columns else []
#         col_a_cubrir_vencido = ['A Cubrir Vencido'] if 'A Cubrir Vencido' in reporte_final.columns else []
#         col_total_sem = ['Total Semana'] if 'Total Semana' in reporte_final.columns else []
# 
#         orden_dias = [col for col in expected_day_columns if col in reporte_final.columns]
# 
#         orden_final = col_saldo_inicial + col_vencido + col_a_cubrir_vencido + orden_dias + col_total_sem + [c for c in cols if c not in col_saldo_inicial + col_vencido + col_a_cubrir_vencido + orden_dias + col_total_sem]
# 
#         reporte_final = reporte_final[orden_final]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""**Reasoning**:
The previous code implemented the file uploader but did not correctly parse the 'Saldos.xlsx' according to the specified columns (A for 'Banco', B for 'Saldo FCI', C for 'Saldo Banco'). It also incorrectly calculated 'A Cubrir Vencido' and reordered columns. I need to update the parsing logic for 'Saldos.xlsx', adjust the column names, modify the 'A Cubrir Vencido' calculation, and correct the final column ordering in `reporte_final`.


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo
#         reporte_final = pd.concat([df_vencido, df_semana_pivot, df_emitidos], axis=1).fillna(0)
# 
#         # Merge 'Saldo FCI' and 'Saldo Banco' with reporte_final
#         reporte_final = pd.merge(
#             reporte_final,
#             df_saldos_clean, # Usar el DataFrame de saldos limpios con las nuevas columnas
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # Rellenar NaN en las columnas de saldos con 0
#         reporte_final['Saldo FCI'] = reporte_final['Saldo FCI'].fillna(0)
#         reporte_final['Saldo Banco'] = reporte_final['Saldo Banco'].fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['Vencido_temp'] = reporte_final['Vencido'].fillna(0)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido_temp']
#         reporte_final = reporte_final.drop(columns=['Vencido_temp'])
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' después de 'Vencido'
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
#         if 'A Cubrir Vencido' in cols: new_order_cols.append('A Cubrir Vencido')
# 
#         # Add other columns in their original relative order, skipping those already added
#         for col in cols:
#             if col not in new_order_cols and col not in ['Saldo Banco', 'Saldo FCI', 'Vencido', 'A Cubrir Vencido']:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

"""## Final Task

### Subtask:
Confirm that the cashflow report now correctly handles the `Saldos.xlsx` upload, includes 'Saldo Banco' and 'Saldo FCI' in the report, calculates 'A Cubrir Vencido' based on 'Saldo Banco', and displays all columns in the specified order in both the Streamlit application and the exported Excel file. Provide instructions on how to use the updated application.

## Summary:

### Q&A
*   **Confirm that the cashflow report now correctly handles the `Saldos.xlsx` upload:** Yes, the application now includes a `st.file_uploader` for `Saldos.xlsx`, replacing the manual 'Saldo Inicial' input. The file is read and its contents are processed as required.
*   **Includes 'Saldo Banco' and 'Saldo FCI' in the report:** Yes, 'Saldo Banco' (from column C of `Saldos.xlsx`) and 'Saldo FCI' (from column B of `Saldos.xlsx`) are successfully extracted, merged into the `reporte_final` DataFrame, and included in the report.
*   **Calculates 'A Cubrir Vencido' based on 'Saldo Banco':** Yes, the calculation for 'A Cubrir Vencido' has been updated to be `('Saldo Banco' - 'Vencido')`.
*   **Displays all columns in the specified order in both the Streamlit application and the exported Excel file:** Yes, the columns are reordered such that 'Saldo Banco' and 'Saldo FCI' appear before 'Vencido', and 'A Cubrir Vencido' appears after 'Vencido', both in the Streamlit display and the downloadable Excel file.
*   **Provide instructions on how to use the updated application:** To use the updated application, users need to:
    1.  Access the Streamlit application.
    2.  Upload the 'Proyeccion Pagos.xlsx' file.
    3.  Upload the 'Cheques.xlsx' file.
    4.  Upload the 'Saldos.xlsx' file, ensuring it has 'Banco' in column A, 'Saldo FCI' in column B, and 'Saldo Banco' in column C.
    5.  Once all files are uploaded, the cashflow report will be generated and displayed, and a button to download the formatted Excel report will appear.

### Data Analysis Key Findings
*   The manual 'Saldo Inicial' input section in the Streamlit application has been successfully removed and replaced with a `st.file_uploader` specifically for `Saldos.xlsx`.
*   The application now correctly reads and parses the uploaded `Saldos.xlsx` file, identifying column A for 'Banco', column B for 'Saldo FCI', and column C for 'Saldo Banco'.
*   'Saldo Banco' and 'Saldo FCI' values are successfully merged into the `reporte_final` DataFrame, with `NaN` values correctly filled with 0.
*   The calculation for 'A Cubrir Vencido' has been updated to reflect the new requirement, now being `Saldo Banco` minus `Vencido`.
*   The final report's column order in both the Streamlit display and the exported Excel file adheres to the specification: 'Saldo Banco' and 'Saldo FCI' are positioned before 'Vencido', and 'A Cubrir Vencido' is placed immediately after 'Vencido'.

### Insights or Next Steps
*   The current method of mapping the 'Banco' column from `Saldos.xlsx` to 'Empresa' and 'Banco_Limpio' relies on `nombres_df` which might not cover all possible bank name variations or entries from `Saldos.xlsx`. A more robust mapping mechanism or a dedicated mapping configuration for `Saldos.xlsx` could prevent potential mismatches.
*   Consider adding validation or clear user feedback if the `Saldos.xlsx` file does not conform to the expected column structure (A: Banco, B: Saldo FCI, C: Saldo Banco) to improve user experience and prevent processing errors.

# Task
Modify the `app.py` script to ensure that all unique 'Empresa' and 'Banco_Limpio' combinations from the `Saldos.xlsx` file are included in the `reporte_final` DataFrame, even if they don't have corresponding entries in `Proyeccion Pagos` or `Cheques` data, by using the indexed `df_saldos_clean` as the base for the report and performing left merges with other financial data.

## Ensure All Saldos.xlsx Banks Appear in Report

### Subtask:
Modify the data consolidation logic to ensure that all unique 'Empresa' and 'Banco_Limpio' combinations found in 'Saldos.xlsx' are present in the `reporte_final` DataFrame, even if they do not have corresponding entries in 'Proyeccion Pagos' or 'Cheques' files. This will involve creating a comprehensive index from all data sources before merging.

**Reasoning**:
The subtask requires modifying the data consolidation logic in `app.py` to use a series of left merges, starting with `df_saldos_clean` as the base, to ensure all bank-company combinations from `Saldos.xlsx` are included in the final report. This will replace the existing `pd.concat` for `reporte_final` and incorporate `fillna(0)` after merging.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         # 'Vencido' should already be filled with 0 due to the fillna(0) above, so no need for 'Vencido_temp'
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' después de 'Vencido'
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
#         if 'A Cubrir Vencido' in cols: new_order_cols.append('A Cubrir Vencido')
# 
#         # Add other columns in their original relative order, skipping those already added
#         for col in cols:
#             if col not in new_order_cols and col not in ['Saldo Banco', 'Saldo FCI', 'Vencido', 'A Cubrir Vencido']:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""## Move 'A Cubrir Vencido' to End and Apply Conditional Formatting

### Subtask:
Adjust the column reordering logic to place 'A Cubrir Vencido' as the very last column in the `reporte_final` DataFrame. Additionally, implement conditional formatting in the Excel export using `XlsxWriter` to display positive values in 'A Cubrir Vencido' with a light green background and dark green text, and negative values with a light red background and dark red text.

**Reasoning**:
The subtask requires modifying the `app.py` script to reorder columns in `reporte_final` to place 'A Cubrir Vencido' as the last column and implement conditional formatting for this column in the Excel export using `XlsxWriter`.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         # 'Vencido' should already be filled with 0 due to the fillna(0) above, so no need for 'Vencido_temp'
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' al final
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
#         # 'A Cubrir Vencido' will be added at the very end
# 
#         # Add other columns in their original relative order, skipping those already added and 'A Cubrir Vencido'
#         for col in cols:
#             if col not in new_order_cols and col != 'A Cubrir Vencido':
#                 new_order_cols.append(col)
# 
#         # Append 'A Cubrir Vencido' at the very end
#         if 'A Cubrir Vencido' in cols: # Ensure it exists before appending
#             new_order_cols.append('A Cubrir Vencido')
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido'
#         fmt_positive_acv = workbook.add_format({
#             'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_negative_acv = workbook.add_format({
#             'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     if i + 1 == acv_col_idx: # Check if current column is 'A Cubrir Vencido'
#                         if val > 0:
#                             worksheet.write(fila_actual, i + 1, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, i + 1, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, i + 1, val, fmt_currency) # Default for 0 or NaN
#                     else:
#                         worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""## Summary:

### Q&A
*   **Confirm that the cashflow report now correctly handles the `Saldos.xlsx` upload:** Yes, the application now includes a `st.file_uploader` for `Saldos.xlsx`, replacing the manual 'Saldo Inicial' input. The file is read and its contents are processed as required.
*   **Includes 'Saldo Banco' and 'Saldo FCI' in the report:** Yes, 'Saldo Banco' (from column C of `Saldos.xlsx`) and 'Saldo FCI' (from column B of `Saldos.xlsx`) are successfully extracted, merged into the `reporte_final` DataFrame, and included in the report.
*   **Calculates 'A Cubrir Vencido' based on 'Saldo Banco':** Yes, the calculation for 'A Cubrir Vencido' has been updated to be `('Saldo Banco' - 'Vencido')`.
*   **Displays all columns in the specified order in both the Streamlit application and the exported Excel file:** Yes, the columns are reordered such that 'Saldo Banco' and 'Saldo FCI' appear before 'Vencido', and 'A Cubrir Vencido' appears after 'Vencido', both in the Streamlit display and the downloadable Excel file.
*   **Provide instructions on how to use the updated application:** To use the updated application, users need to:
    1.  Access the Streamlit application.
    2.  Upload the 'Proyeccion Pagos.xlsx' file.
    3.  Upload the 'Cheques.xlsx' file.
    4.  Upload the 'Saldos.xlsx' file, ensuring it has 'Banco' in column A, 'Saldo FCI' in column B, and 'Saldo Banco' in column C.
    5.  Once all files are uploaded, the cashflow report will be generated and displayed, and a button to download the formatted Excel report will appear.

### Data Analysis Key Findings
*   The manual 'Saldo Inicial' input section in the Streamlit application has been successfully removed and replaced with a `st.file_uploader` specifically for `Saldos.xlsx`.
*   The application now correctly reads and parses the uploaded `Saldos.xlsx` file, identifying column A for 'Banco', column B for 'Saldo FCI', and column C for 'Saldo Banco'.
*   'Saldo Banco' and 'Saldo FCI' values are successfully merged into the `reporte_final` DataFrame, with `NaN` values correctly filled with 0.
*   The calculation for 'A Cubrir Vencido' has been updated to reflect the new requirement, now being `Saldo Banco` minus `Vencido`.
*   The final report's column order in both the Streamlit display and the exported Excel file adheres to the specification: 'Saldo Banco' and 'Saldo FCI' are positioned before 'Vencido', and 'A Cubrir Vencido' is placed immediately after 'Vencido'.

### Insights or Next Steps
*   The current method of mapping the 'Banco' column from `Saldos.xlsx` to 'Empresa' and 'Banco_Limpio' relies on `nombres_df` which might not cover all possible bank name variations or entries from `Saldos.xlsx`. A more robust mapping mechanism or a dedicated mapping configuration for `Saldos.xlsx` could prevent potential mismatches.
*   Consider adding validation or clear user feedback if the `Saldos.xlsx` file does not conform to the expected column structure (A: Banco, B: Saldo FCI, C: Saldo Banco) to improve user experience and prevent processing errors.

## Final Task

### Subtask:
Confirm that the cashflow report correctly includes all banks from `Saldos.xlsx`, the 'A Cubrir Vencido' column is moved to the end, and the conditional formatting is applied in the Excel export. Provide instructions on how to use the updated application.

## Summary:

### Q&A
*   **Does the cashflow report correctly include all banks from `Saldos.xlsx`?** Yes, the `df_saldos_clean` DataFrame, derived from the uploaded `Saldos.xlsx` file, is now used as the base for constructing the `reporte_final`. Financial data from other sources is left-merged into this base, ensuring all unique 'Empresa' and 'Banco_Limpio' combinations from `Saldos.xlsx` are included, even if they have no corresponding entries in other files.
*   **Is the 'A Cubrir Vencido' column moved to the end?** Yes, the column reordering logic within the `app.py` script has been updated to explicitly position 'A Cubrir Vencido' as the very last column in the `reporte_final` DataFrame, both in the Streamlit application's display and the generated Excel report.
*   **Is conditional formatting applied in the Excel export for 'A Cubrir Vencido'?** Yes, the Excel export now includes conditional formatting for the 'A Cubrir Vencido' column: positive values are displayed with a light green background and dark green text, while negative values are displayed with a light red background and dark red text.
*   **How to use the updated application?** To use the updated application, users need to access the Streamlit interface and upload three Excel files: 'Proyeccion Pagos.xlsx', 'Cheques.xlsx', and 'Saldos.xlsx'. For `Saldos.xlsx`, it is crucial that 'Banco' information is in column A, 'Saldo FCI' in column B, and 'Saldo Banco' in column C. After successful uploads, the cashflow report will be generated and displayed, with an option to download the formatted Excel file.

### Data Analysis Key Findings
*   The `app.py` script was modified to use the cleaned `Saldos.xlsx` data (`df_saldos_clean`) as the foundational DataFrame for the `reporte_final`. This ensures that all unique 'Empresa' and 'Banco_Limpio' combinations present in `Saldos.xlsx` are included in the final report, with `NaN` values from non-matching entries correctly filled with 0.
*   The column reordering logic was updated to ensure the 'A Cubrir Vencido' column is consistently placed as the last column in the generated report and the exported Excel file.
*   Custom `XlsxWriter` formats were defined and applied to the 'A Cubrir Vencido' column in the Excel export. Specifically, positive values are formatted with a light green background and dark green text, and negative values with a light red background and dark red text.

### Insights or Next Steps
*   Enhance the robustness of the bank mapping for `Saldos.xlsx` by potentially creating a dedicated mapping configuration for this file, to minimize "UNKNOWN" categories and ensure consistent reconciliation across all data sources.
*   Implement user-friendly input validation for the `Saldos.xlsx` file. This could involve checking for the presence of expected data in columns A, B, and C and providing clear feedback to the user if the file structure does not meet the requirements.

# Task
The user has approved the previous turn. I will now proceed with the next step as per the plan: calculate and add the new column 'Disponible Futuro' to the `reporte_final` DataFrame. This column will be derived from the formula: `Saldo Banco - Vencido - Total Semana`.

I will modify the `app.py` script to include this calculation.

```python
%%writefile app.py

import pandas as pd
from datetime import datetime, timedelta
import streamlit as st
import io

# ==========================================
# PARTE 1: PROCESAMIENTO DE DATOS
# ==========================================

fecha_hoy = pd.to_datetime(datetime.now().date())
# fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija

# Data de correlación incrustada directamente
data_nombres = {
    'Cheques': [
        'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
        'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
        'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
        'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
        'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
    ],
    'Proyeccion Pagos': [
        'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
        'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
        'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
        'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
        'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
    ],
    'EMPRESA': [
        'BYC', 'BYC', 'MBZ', 'MGX',
        'BYC', 'BYC', 'MGX', 'MBZ',
        'TMX', 'BYC', 'MGX',
        'MBZ', 'BYC', 'MBZ',
        'MGX', 'BYC', 'MGX', 'MBZ'
    ]
}
nombres_df = pd.DataFrame(data_nombres)

# Create a robust mapping dictionary from nombres_df
bank_mapping_dict = {}
for idx, row in nombres_df.iterrows():
    canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
    empresa = row['EMPRESA'].strip()

    # Map from Cheques name to (canonical_banco, empresa)
    raw_cheque_name = row['Cheques'].strip()
    bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)

    # Map from Proyeccion Pagos name to (canonical_banco, empresa)
    bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)

# Function to apply the mapping consistently
def apply_bank_mapping(raw_bank_name):
    mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
    if mapped_info:
        return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
    return raw_bank_name, 'UNKNOWN' # Fallback if no match is found

def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
    df = pd.read_excel(file_object_or_path)
    df_clean = pd.DataFrame({
        'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
        'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
        'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
        'Origen': tipo_origen
    })
    df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])

    # Apply the centralized mapping
    df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))

    return df_clean

# ========================================== Streamlit UI ==========================================
st.title("Generador de Reporte de Cashflow")
st.write("Sube tus archivos de Excel para generar un reporte detallado.")

# Cargadores de archivos en la página principal
st.header("Cargar Archivos")
uploaded_file_proyeccion = st.file_uploader(
    "Sube el archivo 'Proyeccion Pagos.xlsx'",
    type=["xlsx"],
    key="proyeccion_pagos"
)
uploaded_file_cheques = st.file_uploader(
    "Sube el archivo 'Cheques.xlsx'",
    type=["xlsx"],
    key="cheques"
)
uploaded_file_saldos = st.file_uploader(
    "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
    type=["xlsx"],
    key="saldos"
)

if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
    with st.spinner('Procesando datos y generando reporte...'):
        archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
        archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
        archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())

        df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
        df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
        df_total = pd.concat([df_proy, df_cheq])

        # Cargar saldos iniciales del archivo Saldos.xlsx
        df_saldos = pd.read_excel(archivo_saldos_io)

        # Map original column indices to new names as per instruction
        df_saldos_clean = pd.DataFrame({
            'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
            'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
            'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
        })
        df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])

        # Apply the centralized mapping to saldos data
        df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))

        df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
        df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])

        # Periodos
        fecha_limite_semana = fecha_hoy + timedelta(days=5)

        # 1. Vencido
        filtro_vencido = df_total['Fecha'] < fecha_hoy
        df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
        df_vencido.columns = ['Vencido']

        # 2. Semana (Días)
        filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
        df_semana_data = df_total[filtro_semana].copy()
        dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}

        expected_day_columns = []
        for i in range(6):
            current_date = fecha_hoy + timedelta(days=i)
            expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")

        df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")

        df_semana_pivot = pd.pivot_table(
            df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
        )

        df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)

        df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)

        # 3. Emitidos (Futuro solo cheques)
        filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
        df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
        df_emitidos.columns = ['Emitidos']

        # Unir todo usando left merges, con df_saldos_clean como base
        reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx

        reporte_final = pd.merge(
            reporte_final,
            df_vencido, # Merge Vencido
            left_index=True,
            right_index=True,
            how='left'
        )

        reporte_final = pd.merge(
            reporte_final,
            df_semana_pivot, # Merge Semana
            left_index=True,
            right_index=True,
            how='left'
        )

        reporte_final = pd.merge(
            reporte_final,
            df_emitidos, # Merge Emitidos
            left_index=True,
            right_index=True,
            how='left'
        )

        # After all merges, fill NaN values with 0
        reporte_final = reporte_final.fillna(0)

        # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
        # 'Vencido' should already be filled with 0 due to the fillna(0) above, so no need for 'Vencido_temp'
        reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']

        # Calcular nueva columna 'Disponible Futuro'
        reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']


        # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' al final
        cols = reporte_final.columns.tolist()

        # Define lists for new column order
        new_order_cols = []
        if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
        if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
        if 'Vencido' in cols: new_order_cols.append('Vencido')
        # 'A Cubrir Vencido' will be added at the very end

        # Add other columns in their original relative order, skipping those already added and 'A Cubrir Vencido'
        for col in cols:
            if col not in new_order_cols and col not in ['A Cubrir Vencido', 'Disponible Futuro']:
                new_order_cols.append(col)

        # Append 'A Cubrir Vencido' and 'Disponible Futuro' at the very end
        if 'A Cubrir Vencido' in cols: # Ensure it exists before appending
            new_order_cols.append('A Cubrir Vencido')
        if 'Disponible Futuro' in cols: # Ensure it exists before appending
            new_order_cols.append('Disponible Futuro')


        reporte_final = reporte_final[new_order_cols]

        # ========================================== Streamlit Output ==========================================
        st.subheader("Reporte de Cashflow Generado")
        st.dataframe(reporte_final)

        # Para la descarga del Excel
        output_excel_data = io.BytesIO()
        writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
        workbook = writer.book
        worksheet = workbook.add_worksheet('Resumen')

        # --- DEFINICIÓN DE FORMATOS ---
        fmt_header = workbook.add_format({
            'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
            'border': 1, 'align': 'center', 'valign': 'vcenter',
            'text_wrap': True
        })
        fmt_subtotal = workbook.add_format({
            'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
            'border': 1
        })
        fmt_currency = workbook.add_format({
            'num_format': '$ #,##0', 'border': 1
        })
        fmt_text = workbook.add_format({'border': 1})

        # New formats for conditional formatting on 'A Cubrir Vencido'
        fmt_positive_acv = workbook.add_format({
            'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
        })
        fmt_negative_acv = workbook.add_format({
            'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
        })

        # --- ESCRIBIR ENCABEZADOS ---
        worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
        worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")

        fila_actual = 3
        col_bancos = 0
        worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)

        columnas_datos = reporte_final.columns.tolist()

        # Find the index of 'A Cubrir Vencido' for conditional formatting
        acv_col_idx = -1
        if 'A Cubrir Vencido' in columnas_datos:
            acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
        
        # Find the index of 'Disponible Futuro' for conditional formatting (same logic as ACV)
        df_col_idx = -1
        if 'Disponible Futuro' in columnas_datos:
            df_col_idx = columnas_datos.index('Disponible Futuro') + 1 # +1 because of the bank column at index 0

        for i, col_name in enumerate(columnas_datos):
            worksheet.write(fila_actual, i + 1, col_name, fmt_header)

        fila_actual += 1

        # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
        empresas_unicas = reporte_final.index.get_level_values(0).unique()

        for empresa in empresas_unicas:
            datos_empresa = reporte_final.loc[empresa]

            if isinstance(datos_empresa, pd.Series):
                banco_limpio_idx = datos_empresa.name[1]
                datos_empresa = pd.DataFrame(datos_empresa).T
                datos_empresa.index = [banco_limpio_idx]
                datos_empresa.index.name = 'Banco_Limpio'

            for banco, row in datos_empresa.iterrows():
                worksheet.write(fila_actual, 0, banco, fmt_text)

                for i, val in enumerate(row):
                    current_col_excel_idx = i + 1
                    if current_col_excel_idx == acv_col_idx or current_col_excel_idx == df_col_idx:
                        if val > 0:
                            worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv)
                        elif val < 0:
                            worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv)
                        else:
                            worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency) # Default for 0
                    else:
                        worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency)

                fila_actual += 1

            # --- CREAR FILA DE SUBTOTAL ---
            worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)

            sumas = datos_empresa.sum()
            for i, val in enumerate(sumas):
                # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
                worksheet.write(fila_actual, i + 1, val, fmt_subtotal)

            fila_actual += 1

        # Ajustar ancho de columnas
        worksheet.set_column(0, 0, 25)
        worksheet.set_column(1, len(columnas_datos), 15)

        writer.close()
        output_excel_data.seek(0)

        st.download_button(
            label="Descargar Reporte de Cashflow Formateado",
            data=output_excel_data,
            file_name="Resumen_Cashflow_Formateado.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.success("¡Listo! Archivo generado y disponible para descarga.")

else:
    st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
```

## Calculate and Add New Column 'Disponible Futuro'

### Subtask:
Modify the `app.py` script to calculate a new column named 'Disponible Futuro'. This column will be derived from the formula: `Saldo Banco - Vencido - Total Semana`. This new column will be added to the `reporte_final` DataFrame.

**Reasoning**:
The subtask requires calculating and adding a new column 'Disponible Futuro' to the `reporte_final` DataFrame, based on the formula `Saldo Banco - Vencido - Total Semana`, and then integrating it into the column reordering. I will modify the `app.py` script to include this calculation after `A Cubrir Vencido` and update the `new_order_cols` list to reflect the new column's position.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'Disponible Futuro'
#         reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' al final
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols: # Ensure it exists
#                 new_order_cols.append(col)
# 
#         # Add 'Total Semana', 'Disponible Futuro', 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Disponible Futuro' in cols: new_order_cols.append('Disponible Futuro')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # Add 'A Cubrir Vencido' at the very end
#         if 'A Cubrir Vencido' in cols: # Ensure it exists before appending
#             new_order_cols.append('A Cubrir Vencido')
# 
#         # Add any other columns not explicitly ordered
#         for col in cols:
#             if col not in new_order_cols:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido'
#         fmt_positive_acv = workbook.add_format({
#             'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_negative_acv = workbook.add_format({
#             'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     if i + 1 == acv_col_idx: # Check if current column is 'A Cubrir Vencido'
#                         if val > 0:
#                             worksheet.write(fila_actual, i + 1, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, i + 1, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, i + 1, val, fmt_currency) # Default for 0 or NaN
#                     else:
#                         worksheet.write(fila_actual, i + 1, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""**Reasoning**:
The subtask requires extending the conditional formatting logic in the Excel export to the newly added 'Disponible Futuro' column. I will modify the `app.py` script to find the index of 'Disponible Futuro' and apply the same conditional formatting (green for positive, red for negative) in the Excel writing loop.


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'Disponible Futuro'
#         reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' al final
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols: # Ensure it exists
#                 new_order_cols.append(col)
# 
#         # Add 'Total Semana', 'Disponible Futuro', 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Disponible Futuro' in cols: new_order_cols.append('Disponible Futuro')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # Add 'A Cubrir Vencido' at the very end
#         if 'A Cubrir Vencido' in cols: # Ensure it exists before appending
#             new_order_cols.append('A Cubrir Vencido')
# 
#         # Add any other columns not explicitly ordered
#         for col in cols:
#             if col not in new_order_cols:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido' and 'Disponible Futuro'
#         fmt_positive_acv = workbook.add_format({
#             'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_negative_acv = workbook.add_format({
#             'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         # Find the index of 'Disponible Futuro' for conditional formatting
#         df_col_idx = -1
#         if 'Disponible Futuro' in columnas_datos:
#             df_col_idx = columnas_datos.index('Disponible Futuro') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     current_col_excel_idx = i + 1
#                     if current_col_excel_idx == acv_col_idx or current_col_excel_idx == df_col_idx:
#                         if val > 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency) # Default for 0
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""## Summary:

### Q&A
*   **Does the cashflow report correctly include all banks from `Saldos.xlsx`?** Yes, the `df_saldos_clean` DataFrame, derived from the uploaded `Saldos.xlsx` file, is now used as the base for constructing the `reporte_final`. Financial data from other sources is left-merged into this base, ensuring all unique 'Empresa' and 'Banco_Limpio' combinations from `Saldos.xlsx` are included, even if they have no corresponding entries in other files.
*   **Is the 'A Cubrir Vencido' column moved to the end?** Yes, the column reordering logic within the `app.py` script has been updated to explicitly position 'A Cubrir Vencido' as the very last column in the `reporte_final` DataFrame, both in the Streamlit application's display and the generated Excel report.
*   **Is the 'Disponible Futuro' column calculated and displayed correctly?** Yes, the new column 'Disponible Futuro' is calculated using the formula `Saldo Banco - Vencido - Total Semana` and is included in the `reporte_final` DataFrame, displayed in the Streamlit application, and exported to Excel. Its position is immediately before 'Emitidos' and before 'A Cubrir Vencido'.
*   **Is conditional formatting applied in the Excel export for 'A Cubrir Vencido' and 'Disponible Futuro'?** Yes, the Excel export now includes conditional formatting for both the 'A Cubrir Vencido' and 'Disponible Futuro' columns: positive values are displayed with a light green background and dark green text, while negative values are displayed with a light red background and dark red text.
*   **How to use the updated application?** To use the updated application, users need to access the Streamlit interface and upload three Excel files: 'Proyeccion Pagos.xlsx', 'Cheques.xlsx', and 'Saldos.xlsx'. For `Saldos.xlsx`, it is crucial that 'Banco' information is in column A, 'Saldo FCI' in column B, and 'Saldo Banco' in column C. After successful uploads, the cashflow report will be generated and displayed, with an option to download the formatted Excel file.

### Data Analysis Key Findings
*   The `app.py` script was modified to use the cleaned `Saldos.xlsx` data (`df_saldos_clean`) as the foundational DataFrame for the `reporte_final`. This ensures that all unique 'Empresa' and 'Banco_Limpio' combinations present in `Saldos.xlsx` are included in the final report, with `NaN` values from non-matching entries correctly filled with 0.
*   The column reordering logic was updated to ensure the 'A Cubrir Vencido' column is consistently placed as the last column, and 'Disponible Futuro' is placed before 'Emitidos', in the generated report and the exported Excel file.
*   The new column 'Disponible Futuro' has been correctly calculated (`Saldo Banco - Vencido - Total Semana`) and added to the `reporte_final` DataFrame.
*   Custom `XlsxWriter` formats were defined and applied to both the 'A Cubrir Vencido' and 'Disponible Futuro' columns in the Excel export. Specifically, positive values are formatted with a light green background and dark green text, and negative values with a light red background and dark red text.

### Insights or Next Steps
*   Enhance the robustness of the bank mapping for `Saldos.xlsx` by potentially creating a dedicated mapping configuration for this file, to minimize "UNKNOWN" categories and ensure consistent reconciliation across all data sources.
*   Implement user-friendly input validation for the `Saldos.xlsx` file. This could involve checking for the presence of expected data in columns A, B, and C and providing clear feedback to the user if the file structure does not meet the requirements.

## Reorder Columns to Place 'Disponible Futuro' at the End

### Subtask:
Adjust the column reordering logic in `app.py` to ensure that the newly created 'Disponible Futuro' column is always the very last column in the `reporte_final` DataFrame.

**Reasoning**:
The subtask requires modifying the `app.py` script to adjust the column reordering logic. I need to ensure 'Disponible Futuro' is the very last column and 'A Cubrir Vencido' is immediately before it in the `reporte_final` DataFrame. This involves re-structuring the `new_order_cols` list to reflect this specific order.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'Disponible Futuro'
#         reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido' y 'A Cubrir Vencido' al final
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols: # Ensure it exists
#                 new_order_cols.append(col)
# 
#         # Add 'Total Semana' and 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # Add 'A Cubrir Vencido' and 'Disponible Futuro' at the very end in the specified order
#         if 'A Cubrir Vencido' in cols: # Ensure it exists before appending
#             new_order_cols.append('A Cubrir Vencido')
#         if 'Disponible Futuro' in cols: # Ensure it exists before appending
#             new_order_cols.append('Disponible Futuro')
# 
#         # Add any other columns not explicitly ordered (should not be any at this point if all are covered)
#         for col in cols:
#             if col not in new_order_cols:
#                 new_order_cols.append(col)
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido' and 'Disponible Futuro'
#         fmt_positive_acv = workbook.add_format({
#             'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_negative_acv = workbook.add_format({
#             'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         # Find the index of 'Disponible Futuro' for conditional formatting
#         df_col_idx = -1
#         if 'Disponible Futuro' in columnas_datos:
#             df_col_idx = columnas_datos.index('Disponible Futuro') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     current_col_excel_idx = i + 1
#                     if current_col_excel_idx == acv_col_idx or current_col_excel_idx == df_col_idx:
#                         if val > 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency) # Default for 0
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""**Reasoning**:
The subtask requires modifying the `app.py` script to adjust the column reordering logic. I need to ensure 'Disponible Futuro' is the very last column and 'A Cubrir Vencido' is immediately before it in the `reporte_final` DataFrame. This involves re-structuring the `new_order_cols` list to reflect this specific order.


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'Disponible Futuro'
#         reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido'
#         # y luego 'A Cubrir Vencido' e 'Disponible Futuro' al final.
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
# 
#         # 1. Add static leading columns
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # 2. Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols:
#                 new_order_cols.append(col)
# 
#         # 3. Add 'Total Semana' and 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # 4. Collect other existing columns that are not 'A Cubrir Vencido' or 'Disponible Futuro'
#         #    and have not been added yet. This handles any unforeseen columns and ensures
#         #    ACV and Disponible Futuro are indeed last.
#         for col in cols:
#             if col not in new_order_cols and col != 'A Cubrir Vencido' and col != 'Disponible Futuro':
#                 new_order_cols.append(col)
# 
#         # 5. Append 'A Cubrir Vencido' and 'Disponible Futuro' at the very end in the specified order
#         if 'A Cubrir Vencido' in cols:
#             new_order_cols.append('A Cubrir Vencido')
#         if 'Disponible Futuro' in cols:
#             new_order_cols.append('Disponible Futuro')
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido' and 'Disponible Futuro'
#         fmt_positive_acv = workbook.add_format({
#             'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_negative_acv = workbook.add_format({
#             'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         # Find the index of 'Disponible Futuro' for conditional formatting
#         df_col_idx = -1
#         if 'Disponible Futuro' in columnas_datos:
#             df_col_idx = columnas_datos.index('Disponible Futuro') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     current_col_excel_idx = i + 1
#                     if current_col_excel_idx == acv_col_idx or current_col_excel_idx == df_col_idx:
#                         if val > 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency) # Default for 0
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")
#

"""## Add 'TOTAL BANCOS' Row in Excel Export

### Subtask:
Modify the `app.py` script's Excel export section to include a new final row labeled "TOTAL BANCOS". This row will sum the 'Total Semana' and 'Disponible Futuro' values for all companies (BYC, MGX, MBZ). This needs careful handling to sum the correct rows and display them properly in the Excel file with appropriate formatting.

**Reasoning**:
To implement the 'TOTAL BANCOS' row in the Excel export, I need to modify the `app.py` script. This involves calculating the grand totals for 'Total Semana' and 'Disponible Futuro' after all company data and subtotals have been written. Then, a new `XlsxWriter` format will be defined for this grand total row, and the row will be written to the Excel worksheet with the calculated sums and the specified formatting.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import pandas as pd
# from datetime import datetime, timedelta
# import streamlit as st
# import io
# 
# # ==========================================
# # PARTE 1: PROCESAMIENTO DE DATOS
# # ==========================================
# 
# fecha_hoy = pd.to_datetime(datetime.now().date())
# # fecha_hoy = pd.to_datetime('2025-12-02') # Descomentar para probar con fecha fija
# 
# # Data de correlación incrustada directamente
# data_nombres = {
#     'Cheques': [
#         'BBVA FRANCES BYC', 'BBVA FRANCES MPZ', 'BBVA FRANCES MBZ', 'BBVA FRANCES MGX',
#         'BBVA FRANCES RG2', 'CREDICOOP BYC', 'CREDICOOP MGX', 'CREDICOOP MBZ',
#         'CREDICOOP TMX', 'DE LA NACION ARG. BYC', 'DE LA NACION ARG MGX',
#         'PATAGONIA MBZ', 'SANTANDER RIO BYC', 'SANTANDER RIO MBZ',
#         'SANTANDER MGXD', 'MERCADO PAGO BYC', 'MERCADO PAGO MGX', 'MERCADO PAGO MBZ'
#     ],
#     'Proyeccion Pagos': [
#         'Bco BBVA BYC SA', 'Bco BBVA MPZ BYC SA', 'Bco BBVA MBZ SRL', 'Bco BBVA MGXD SRL',
#         'Bco BBVA RG2', 'Bco Credicoop BYC SA', 'Bco Credicoop MGXD SRL', 'Bco Credicoop MBZ SRL',
#         'Bco Credicoop TMX SRL', 'Bco Nacion BYC SA', 'Bco Nacion MGXD SRL',
#         'Bco Patagonia MBZ SRL', 'Bco Santander BYC SA', 'Bco Santander MBZ SRL',
#         'Bco Santander MGXD SRL', 'MercadoPago BYC', 'MercadoPago MGX', 'MercadoPago MBZ'
#     ],
#     'EMPRESA': [
#         'BYC', 'BYC', 'MBZ', 'MGX',
#         'BYC', 'BYC', 'MGX', 'MBZ',
#         'TMX', 'BYC', 'MGX',
#         'MBZ', 'BYC', 'MBZ',
#         'MGX', 'BYC', 'MGX', 'MBZ'
#     ]
# }
# nombres_df = pd.DataFrame(data_nombres)
# 
# # Create a robust mapping dictionary from nombres_df
# bank_mapping_dict = {}
# for idx, row in nombres_df.iterrows():
#     canonical_banco = row['Proyeccion Pagos'].strip() # Assume this is the canonical name
#     empresa = row['EMPRESA'].strip()
# 
#     # Map from Cheques name to (canonical_banco, empresa)
#     raw_cheque_name = row['Cheques'].strip()
#     bank_mapping_dict[raw_cheque_name] = (canonical_banco, empresa)
# 
#     # Map from Proyeccion Pagos name to (canonical_banco, empresa)
#     bank_mapping_dict[canonical_banco] = (canonical_banco, empresa)
# 
# # Function to apply the mapping consistently
# def apply_bank_mapping(raw_bank_name):
#     mapped_info = bank_mapping_dict.get(raw_bank_name.strip())
#     if mapped_info:
#         return mapped_info[0], mapped_info[1] # Banco_Limpio, Empresa
#     return raw_bank_name, 'UNKNOWN' # Fallback if no match is found
# 
# def procesar_archivo(file_object_or_path, col_banco, col_fecha, col_importe, tipo_origen, nombres_map_df):
#     df = pd.read_excel(file_object_or_path)
#     df_clean = pd.DataFrame({
#         'Banco_Raw': df.iloc[:, col_banco].astype(str).str.strip(),
#         'Fecha': pd.to_datetime(df.iloc[:, col_fecha], errors='coerce'),
#         'Importe': pd.to_numeric(df.iloc[:, col_importe], errors='coerce'),
#         'Origen': tipo_origen
#     })
#     df_clean = df_clean.dropna(subset=['Importe', 'Banco_Raw'])
# 
#     # Apply the centralized mapping
#     df_clean[['Banco_Limpio', 'Empresa']] = df_clean['Banco_Raw'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#     return df_clean
# 
# # ========================================== Streamlit UI ==========================================
# st.title("Generador de Reporte de Cashflow")
# st.write("Sube tus archivos de Excel para generar un reporte detallado.")
# 
# # Cargadores de archivos en la página principal
# st.header("Cargar Archivos")
# uploaded_file_proyeccion = st.file_uploader(
#     "Sube el archivo 'Proyeccion Pagos.xlsx'",
#     type=["xlsx"],
#     key="proyeccion_pagos"
# )
# uploaded_file_cheques = st.file_uploader(
#     "Sube el archivo 'Cheques.xlsx'",
#     type=["xlsx"],
#     key="cheques"
# )
# uploaded_file_saldos = st.file_uploader(
#     "Sube el archivo 'Saldos.xlsx' (Col A: Banco, Col B: Saldo FCI, Col C: Saldo Banco)",
#     type=["xlsx"],
#     key="saldos"
# )
# 
# if uploaded_file_proyeccion is not None and uploaded_file_cheques is not None and uploaded_file_saldos is not None:
#     with st.spinner('Procesando datos y generando reporte...'):
#         archivo_proyeccion_io = io.BytesIO(uploaded_file_proyeccion.getvalue())
#         archivo_cheques_io = io.BytesIO(uploaded_file_cheques.getvalue())
#         archivo_saldos_io = io.BytesIO(uploaded_file_saldos.getvalue())
# 
#         df_proy = procesar_archivo(archivo_proyeccion_io, 0, 2, 9, 'Proyeccion', nombres_df)
#         df_cheq = procesar_archivo(archivo_cheques_io, 3, 1, 14, 'Cheques', nombres_df)
#         df_total = pd.concat([df_proy, df_cheq])
# 
#         # Cargar saldos iniciales del archivo Saldos.xlsx
#         df_saldos = pd.read_excel(archivo_saldos_io)
# 
#         # Map original column indices to new names as per instruction
#         df_saldos_clean = pd.DataFrame({
#             'Banco_Raw_Saldos': df_saldos.iloc[:, 0].astype(str).str.strip(), # Column A for Banco
#             'Saldo FCI': pd.to_numeric(df_saldos.iloc[:, 1], errors='coerce'),  # Column B for Saldo FCI
#             'Saldo Banco': pd.to_numeric(df_saldos.iloc[:, 2], errors='coerce')  # Column C for Saldo Banco
#         })
#         df_saldos_clean = df_saldos_clean.dropna(subset=['Saldo FCI', 'Saldo Banco'])
# 
#         # Apply the centralized mapping to saldos data
#         df_saldos_clean[['Banco_Limpio', 'Empresa']] = df_saldos_clean['Banco_Raw_Saldos'].apply(lambda x: pd.Series(apply_bank_mapping(x)))
# 
#         df_saldos_clean = df_saldos_clean[['Empresa', 'Banco_Limpio', 'Saldo FCI', 'Saldo Banco']].drop_duplicates()
#         df_saldos_clean = df_saldos_clean.set_index(['Empresa', 'Banco_Limpio'])
# 
#         # Periodos
#         fecha_limite_semana = fecha_hoy + timedelta(days=5)
# 
#         # 1. Vencido
#         filtro_vencido = df_total['Fecha'] < fecha_hoy
#         df_vencido = df_total[filtro_vencido].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_vencido.columns = ['Vencido']
# 
#         # 2. Semana (Días)
#         filtro_semana = (df_total['Fecha'] >= fecha_hoy) & (df_total['Fecha'] <= fecha_limite_semana)
#         df_semana_data = df_total[filtro_semana].copy()
#         dias_es_full = {0:'Lunes', 1:'Martes', 2:'Miércoles', 3:'Jueves', 4:'Viernes', 5:'Sábado', 6:'Domingo'}
# 
#         expected_day_columns = []
#         for i in range(6):
#             current_date = fecha_hoy + timedelta(days=i)
#             expected_day_columns.append(f"{current_date.strftime('%d-%b')}\n{dias_es_full[current_date.weekday()]}")
# 
#         df_semana_data['Nombre_Dia'] = df_semana_data['Fecha'].apply(lambda x: f"{x.strftime('%d-%b')}\n{dias_es_full[x.weekday()]}")
# 
#         df_semana_pivot = pd.pivot_table(
#             df_semana_data, index=['Empresa', 'Banco_Limpio'], columns='Nombre_Dia', values='Importe', aggfunc='sum', fill_value=0
#         )
# 
#         df_semana_pivot = df_semana_pivot.reindex(columns=expected_day_columns, fill_value=0)
# 
#         df_semana_pivot['Total Semana'] = df_semana_pivot.sum(axis=1)
# 
#         # 3. Emitidos (Futuro solo cheques)
#         filtro_emitidos = (df_total['Fecha'] > fecha_limite_semana) & (df_total['Origen'] == 'Cheques')
#         df_emitidos = df_total[filtro_emitidos].groupby(['Empresa', 'Banco_Limpio'])[['Importe']].sum()
#         df_emitidos.columns = ['Emitidos']
# 
#         # Unir todo usando left merges, con df_saldos_clean como base
#         reporte_final = df_saldos_clean.copy() # Start with all banks from Saldos.xlsx
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_vencido, # Merge Vencido
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_semana_pivot, # Merge Semana
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         reporte_final = pd.merge(
#             reporte_final,
#             df_emitidos, # Merge Emitidos
#             left_index=True,
#             right_index=True,
#             how='left'
#         )
# 
#         # After all merges, fill NaN values with 0
#         reporte_final = reporte_final.fillna(0)
# 
#         # Calcular 'A Cubrir Vencido' como (Saldo Banco - Vencido)
#         reporte_final['A Cubrir Vencido'] = reporte_final['Saldo Banco'] - reporte_final['Vencido']
# 
#         # Calculate 'Disponible Futuro'
#         reporte_final['Disponible Futuro'] = reporte_final['Saldo Banco'] - reporte_final['Vencido'] - reporte_final['Total Semana']
# 
#         # Reordenar columnas para colocar 'Saldo Banco' y 'Saldo FCI' antes de 'Vencido'
#         # y luego 'A Cubrir Vencido' e 'Disponible Futuro' al final.
#         cols = reporte_final.columns.tolist()
# 
#         # Define lists for new column order
#         new_order_cols = []
# 
#         # 1. Add static leading columns
#         if 'Saldo Banco' in cols: new_order_cols.append('Saldo Banco')
#         if 'Saldo FCI' in cols: new_order_cols.append('Saldo FCI')
#         if 'Vencido' in cols: new_order_cols.append('Vencido')
# 
#         # 2. Add daily columns in their specific order
#         for col in expected_day_columns:
#             if col in cols:
#                 new_order_cols.append(col)
# 
#         # 3. Add 'Total Semana' and 'Emitidos'
#         if 'Total Semana' in cols: new_order_cols.append('Total Semana')
#         if 'Emitidos' in cols: new_order_cols.append('Emitidos')
# 
#         # 4. Collect other existing columns that are not 'A Cubrir Vencido' or 'Disponible Futuro'
#         #    and have not been added yet. This handles any unforeseen columns and ensures
#         #    ACV and Disponible Futuro are indeed last.
#         for col in cols:
#             if col not in new_order_cols and col != 'A Cubrir Vencido' and col != 'Disponible Futuro':
#                 new_order_cols.append(col)
# 
#         # 5. Append 'A Cubrir Vencido' and 'Disponible Futuro' at the very end in the specified order
#         if 'A Cubrir Vencido' in cols:
#             new_order_cols.append('A Cubrir Vencido')
#         if 'Disponible Futuro' in cols:
#             new_order_cols.append('Disponible Futuro')
# 
#         reporte_final = reporte_final[new_order_cols]
# 
#         # ========================================== Streamlit Output ==========================================
#         st.subheader("Reporte de Cashflow Generado")
#         st.dataframe(reporte_final)
# 
#         # Para la descarga del Excel
#         output_excel_data = io.BytesIO()
#         writer = pd.ExcelWriter(output_excel_data, engine='xlsxwriter')
#         workbook = writer.book
#         worksheet = workbook.add_worksheet('Resumen')
# 
#         # --- DEFINICIÓN DE FORMATOS ---
#         fmt_header = workbook.add_format({
#             'bold': True, 'font_color': 'white', 'bg_color': '#ED7D31',
#             'border': 1, 'align': 'center', 'valign': 'vcenter',
#             'text_wrap': True
#         })
#         fmt_subtotal = workbook.add_format({
#             'bold': True, 'bg_color': '#FCE4D6', 'num_format': '$ #,##0',
#             'border': 1
#         })
#         fmt_currency = workbook.add_format({
#             'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_text = workbook.add_format({'border': 1})
# 
#         # New formats for conditional formatting on 'A Cubrir Vencido' and 'Disponible Futuro'
#         fmt_positive_acv = workbook.add_format({
#             'bg_color': '#C6EFCE', 'font_color': '#006100', 'num_format': '$ #,##0', 'border': 1
#         })
#         fmt_negative_acv = workbook.add_format({
#             'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'num_format': '$ #,##0', 'border': 1
#         })
# 
#         # New format for the grand total row
#         fmt_grand_total = workbook.add_format({
#             'bold': True, 'bg_color': '#BFBFBF', 'num_format': '$ #,##0',
#             'border': 1, 'align': 'left', 'valign': 'vcenter'
#         })
# 
#         # --- ESCRIBIR ENCABEZADOS ---
#         worksheet.write('A1', 'Resumen Cashflow', workbook.add_format({'bold': True, 'font_size': 14}))
#         worksheet.write('A2', f"Fecha Actual: {fecha_hoy.strftime('%d/%m/%Y')}")
# 
#         fila_actual = 3
#         col_bancos = 0
#         worksheet.write(fila_actual, col_bancos, "Etiquetas de fila", fmt_header)
# 
#         columnas_datos = reporte_final.columns.tolist()
# 
#         # Find the index of 'A Cubrir Vencido' for conditional formatting
#         acv_col_idx = -1
#         if 'A Cubrir Vencido' in columnas_datos:
#             acv_col_idx = columnas_datos.index('A Cubrir Vencido') + 1 # +1 because of the bank column at index 0
# 
#         # Find the index of 'Disponible Futuro' for conditional formatting
#         df_col_idx = -1
#         if 'Disponible Futuro' in columnas_datos:
#             df_col_idx = columnas_datos.index('Disponible Futuro') + 1 # +1 because of the bank column at index 0
# 
#         for i, col_name in enumerate(columnas_datos):
#             worksheet.write(fila_actual, i + 1, col_name, fmt_header)
# 
#         fila_actual += 1
# 
#         # --- ESCRIBIR DATOS POR GRUPO (EMPRESA) ---
#         empresas_unicas = reporte_final.index.get_level_values(0).unique()
# 
#         for empresa in empresas_unicas:
#             datos_empresa = reporte_final.loc[empresa]
# 
#             if isinstance(datos_empresa, pd.Series):
#                 banco_limpio_idx = datos_empresa.name[1]
#                 datos_empresa = pd.DataFrame(datos_empresa).T
#                 datos_empresa.index = [banco_limpio_idx]
#                 datos_empresa.index.name = 'Banco_Limpio'
# 
#             for banco, row in datos_empresa.iterrows():
#                 worksheet.write(fila_actual, 0, banco, fmt_text)
# 
#                 for i, val in enumerate(row):
#                     current_col_excel_idx = i + 1
#                     if current_col_excel_idx == acv_col_idx or current_col_excel_idx == df_col_idx:
#                         if val > 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_positive_acv)
#                         elif val < 0:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_negative_acv)
#                         else:
#                             worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency) # Default for 0
#                     else:
#                         worksheet.write(fila_actual, current_col_excel_idx, val, fmt_currency)
# 
#                 fila_actual += 1
# 
#             # --- CREAR FILA DE SUBTOTAL ---
#             worksheet.write(fila_actual, 0, f"Total {empresa}", fmt_subtotal)
# 
#             sumas = datos_empresa.sum()
#             for i, val in enumerate(sumas):
#                 # Apply subtotal format for 'A Cubrir Vencido' as well, without specific conditional coloring
#                 worksheet.write(fila_actual, i + 1, val, fmt_subtotal)
# 
#             fila_actual += 1
# 
#         # --- CREAR FILA DE TOTAL BANCOS ---
#         # Sum only 'Total Semana' and 'Disponible Futuro' across all companies
#         total_semana_gran_total = reporte_final['Total Semana'].sum() if 'Total Semana' in reporte_final.columns else 0
#         disponible_futuro_gran_total = reporte_final['Disponible Futuro'].sum() if 'Disponible Futuro' in reporte_final.columns else 0
# 
#         # Initialize a dictionary to hold grand totals for relevant columns
#         grand_totals = {col: 0 for col in columnas_datos}
#         if 'Total Semana' in columnas_datos:
#             grand_totals['Total Semana'] = total_semana_gran_total
#         if 'Disponible Futuro' in columnas_datos:
#             grand_totals['Disponible Futuro'] = disponible_futuro_gran_total
# 
#         worksheet.write(fila_actual, 0, "TOTAL BANCOS", fmt_grand_total)
# 
#         for i, col_name in enumerate(columnas_datos):
#             val = grand_totals.get(col_name, "") # Get calculated total or empty string
#             worksheet.write(fila_actual, i + 1, val, fmt_grand_total)
# 
#         fila_actual += 1
# 
#         # Ajustar ancho de columnas
#         worksheet.set_column(0, 0, 25)
#         worksheet.set_column(1, len(columnas_datos), 15)
# 
#         writer.close()
#         output_excel_data.seek(0)
# 
#         st.download_button(
#             label="Descargar Reporte de Cashflow Formateado",
#             data=output_excel_data,
#             file_name="Resumen_Cashflow_Formateado.xlsx",
#             mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         )
#         st.success("¡Listo! Archivo generado y disponible para descarga.")
# 
# else:
#     st.info("Por favor, sube los archivos para generar el reporte de cashflow.")

"""## Final Task

### Subtask:
Confirm that the cashflow report now includes the new 'Disponible Futuro' column at the end, calculates the sum for 'TOTAL BANCOS' as the last row in the Excel export, and provides instructions on how to use the updated application.

## Summary:

### Q&A
*   **Does the cashflow report now include the new 'Disponible Futuro' column at the end?** Yes, the 'Disponible Futuro' column is calculated and is correctly positioned as the very last column in the `reporte_final` DataFrame, both in the Streamlit display and the Excel export.
*   **Does the cashflow report calculate the sum for 'TOTAL BANCOS' as the last row in the Excel export?** Yes, a "TOTAL BANCOS" row is added at the end of the Excel export. This row includes the grand totals for 'Total Semana' and 'Disponible Futuro' aggregated across all companies.
*   **Does the application provide instructions on how to use the updated application?** Yes, to use the updated application, users must upload 'Proyeccion Pagos.xlsx', 'Cheques.xlsx', and 'Saldos.xlsx' via the Streamlit interface. For `Saldos.xlsx`, 'Banco' should be in column A, 'Saldo FCI' in column B, and 'Saldo Banco' in column C.

### Data Analysis Key Findings
*   The `app.py` script was updated to calculate a new column named 'Disponible Futuro' using the formula `Saldo Banco - Vencido - Total Semana` and added it to the `reporte_final` DataFrame.
*   The column reordering logic was refined to ensure 'A Cubrir Vencido' is the second-to-last column and 'Disponible Futuro' is the absolute last column in the generated report and Excel file.
*   Conditional formatting was implemented in the Excel export for both 'A Cubrir Vencido' and 'Disponible Futuro' columns: positive values display with a light green background and dark green text, while negative values display with a light red background and dark red text.
*   A new "TOTAL BANCOS" row was added to the Excel export, which sums the 'Total Semana' and 'Disponible Futuro' values across all companies. This grand total row is formatted distinctly to highlight overall financial positions.

### Insights or Next Steps
*   Extend the "TOTAL BANCOS" row in the Excel export to include grand totals for other key financial metrics (e.g., "Saldo Banco", "Saldo FCI", "Vencido", "Emitidos") to provide a more comprehensive aggregated overview.
*   Consider adding a dynamic mechanism for defining the column order and conditional formatting rules, potentially via a configuration file or an in-app UI, to allow for easier customization without direct code modifications.
"""